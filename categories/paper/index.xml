<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>论文 on 德斯别尔-Des</title>
        <link>https://deisbeir.github.io/categories/paper/</link>
        <description>Recent content in 论文 on 德斯别尔-Des</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>德斯别尔-Des</copyright>
        <lastBuildDate>Tue, 14 Jan 2025 11:49:34 +0800</lastBuildDate><atom:link href="https://deisbeir.github.io/categories/paper/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Matrix_Factorization</title>
        <link>https://deisbeir.github.io/p/matrix_factorization/</link>
        <pubDate>Tue, 14 Jan 2025 11:49:34 +0800</pubDate>
        
        <guid>https://deisbeir.github.io/p/matrix_factorization/</guid>
        <description>&lt;img src="https://deisbeir.github.io/p/matrix_factorization/show.png" alt="Featured image of post Matrix_Factorization" /&gt;&lt;h3 id=&#34;论文总结matrix-factorization-techniques-for-recommender-systems&#34;&gt;论文总结：&lt;strong&gt;Matrix Factorization Techniques for Recommender Systems&lt;/strong&gt;
&lt;/h3&gt;&lt;img src=&#34;1.png&#34; alt=&#34;image-20250114122454762&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ABSTRACT&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;​		As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.&lt;/p&gt;
&lt;p&gt;​		本论文深入探讨了 Netflix 推荐系统中使用的矩阵分解技术及其在协同过滤领域的优越性。通过将用户和项目映射到隐变量空间，该技术能够捕捉用户与项目间的复杂交互。论文强调了矩阵分解模型在整合时间动态、隐式反馈和偏差建模等方面的灵活性，并通过 Netflix Prize 数据集验证了其对推荐质量的显著提升。&lt;/p&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景
&lt;/h3&gt;&lt;p&gt;随着电子商务和内容平台的发展，推荐系统在为用户提供个性化服务方面发挥了重要作用。Netflix 推荐系统基于协同过滤，旨在分析用户对电影的评分模式，以预测未来的观看偏好。&lt;/p&gt;
&lt;p&gt;推荐系统主要分为两类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;基于内容过滤&lt;/strong&gt;：通过分析用户和项目的属性特征匹配用户与项目。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;协同过滤&lt;/strong&gt;：利用用户行为（如评分或购买记录）预测用户兴趣。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Netflix 系统采用协同过滤方法，其中矩阵分解模型通过隐变量空间的表示，解决了传统最近邻方法的可扩展性和精度不足问题。&lt;/p&gt;
&lt;h3 id=&#34;主要发现&#34;&gt;主要发现
&lt;/h3&gt;&lt;h4 id=&#34;1-矩阵分解技术的优越性&#34;&gt;1. 矩阵分解技术的优越性
&lt;/h4&gt;&lt;p&gt;矩阵分解模型是协同过滤中最成功的方法之一，其核心思想是将用户和项目嵌入到同一个隐变量空间，通过内积建模用户与项目的交互。具体特性包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;高效建模用户和项目&lt;/strong&gt;：&lt;/p&gt;
$$
  \hat{r}_{ui} = \mu + b_u + b_i + q_i^T p_u
  $$&lt;ul&gt;
&lt;li&gt;$ \mu $ ：全局平均评分。&lt;/li&gt;
&lt;li&gt;$b_u$ ，$ b_i $：用户和项目的评分偏差。&lt;/li&gt;
&lt;li&gt;$q_i$，$p_u$：项目和用户的隐变量向量，捕捉用户偏好与项目特性。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;灵活性&lt;/strong&gt;： 模型能够自然整合时间动态、隐式反馈和偏差等多种数据特性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;高效性与准确性&lt;/strong&gt;： 实验表明矩阵分解模型显著优于基于用户或项目的最近邻算法，能够以较低计算成本提供更高的预测精度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-时间动态的影响&#34;&gt;2. 时间动态的影响
&lt;/h4&gt;&lt;p&gt;用户偏好和项目流行度随时间变化，矩阵分解模型通过动态调整用户和项目的特性向量来捕捉这些变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用户评分基线随时间漂移（如评分标准变宽或变严）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目流行度因外部事件（如电影奖项、演员活动）而变化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
  \hat{r}_{ui}(t) = \mu + b_i(t) + b_u(t) + q_i^T p_u(t)
  $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;时间动态的加入显著降低了预测误差，尤其是在用户行为变化频繁的场景中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-隐式反馈的整合&#34;&gt;3. 隐式反馈的整合
&lt;/h4&gt;&lt;p&gt;Netflix 推荐系统能够利用隐式反馈（如观看时长、点击行为）弥补评分数据稀疏的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;隐式反馈以用户行为的存在或频率作为信号（如某用户购买或观看某项目的次数）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$
  \hat{r}_{ui} = \mu + b_u + b_i + q_i^T \left(p_u + |N(u)|^{-0.5} \sum_{i \in N(u)} x_i\right)
  $$&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验显示，隐式反馈的加入能够提升冷启动用户和项目的推荐效果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;4-偏差建模的贡献&#34;&gt;4. 偏差建模的贡献
&lt;/h4&gt;&lt;p&gt;评分数据中存在系统偏差，如部分用户倾向于高评分或部分项目因质量优秀获得更多高分。模型显式分离偏差成分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ \mu $：全局评分平均值。&lt;/li&gt;
&lt;li&gt;$b_u$：用户评分偏差，表示用户对全局评分的偏离程度。&lt;/li&gt;
&lt;li&gt;$ b_i $：项目评分偏差，表示项目质量或流行度的平均影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过分离这些偏差，模型更准确地捕捉用户与项目间的真实交互。&lt;/p&gt;
&lt;h4 id=&#34;5-并行化和扩展性&#34;&gt;5. 并行化和扩展性
&lt;/h4&gt;&lt;p&gt;矩阵分解技术具有良好的并行化能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;随机梯度下降（SGD）&lt;/strong&gt;：快速优化模型参数，适用于稀疏数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;交替最小二乘法（ALS）&lt;/strong&gt;：支持并行化计算，适合处理大规模隐式数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Netflix 数据集上，ALS 方法能有效应对数据规模增长，同时保持高精度。&lt;/p&gt;
&lt;h4 id=&#34;6-实验结果验证&#34;&gt;6. 实验结果验证
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;使用 Netflix Prize 数据集（1 亿条评分，500,000 用户和 17,000 项目），评估模型在不同特性下的表现：
&lt;ul&gt;
&lt;li&gt;Netflix 原始系统 RMSE 为 0.9514，扩展模型将其降低至 0.8563，达到竞赛目标。&lt;/li&gt;
&lt;li&gt;时间动态和隐式反馈的加入显著提升了冷启动和长期预测的效果。&lt;/li&gt;
&lt;li&gt;不同维度的隐变量设置表明，增加维度能提升模型性能，但过高可能导致过拟合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;结论&#34;&gt;结论
&lt;/h3&gt;&lt;p&gt;Netflix 推荐系统通过矩阵分解技术实现了协同过滤的突破性进展：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;灵活捕捉用户与项目间的复杂交互。&lt;/li&gt;
&lt;li&gt;高效处理大规模稀疏数据，并显著提升推荐质量。&lt;/li&gt;
&lt;li&gt;成功整合时间动态、隐式反馈和偏差建模，扩展了推荐系统的适用场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些技术为现代电子商务和流媒体平台的推荐系统设计提供了重要的参考和方向。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ItemCF</title>
        <link>https://deisbeir.github.io/p/itemcf/</link>
        <pubDate>Mon, 13 Jan 2025 17:45:37 +0800</pubDate>
        
        <guid>https://deisbeir.github.io/p/itemcf/</guid>
        <description>&lt;img src="https://deisbeir.github.io/p/itemcf/show.png" alt="Featured image of post ItemCF" /&gt;&lt;h3 id=&#34;论文总结item-based-collaborative-filtering-recommendation-algorithms&#34;&gt;论文总结：&lt;em&gt;Item-Based Collaborative Filtering Recommendation Algorithms&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://deisbeir.github.io/p/itemcf/1.png&#34;
	width=&#34;988&#34;
	height=&#34;280&#34;
	srcset=&#34;https://deisbeir.github.io/p/itemcf/1_hu1346023622882188747.png 480w, https://deisbeir.github.io/p/itemcf/1_hu17807581507284861765.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;352&#34;
		data-flex-basis=&#34;846px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ABSTRACT&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;​			Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction. These systems, especially the k-nearest neighbor collaborative ltering based ones, are achieving widespread success on the Web. The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity. In traditional collaborative ltering systems the amount of work increases with the number of participants in the system. New recommender system technologies are needed that can quickly produce high quality recom- mendations, even for very large-scale problems. To address these issues we have explored item-based collaborative ltering techniques. Item-based techniques rst analyze the user-item matrix to identify relationships between dierent items, and then use these relationships to indirectly compute recommendations for users.&lt;/p&gt;
&lt;p&gt;​			In this paper we analyze dierent item-based recommendation generation algorithms. We look into dierent techniques for computing item-item similarities (e.g., item-item correlation vs. cosine similarities between item vectors) and dierent techniques for obtaining recommendations from them (e.g., weighted sum vs. regression model). Finally, we ex- perimentally evaluate our results and compare them to the basic k-nearest neighbor approach. Our experiments suggest that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available userbased algorithms.&lt;/p&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景
&lt;/h3&gt;&lt;p&gt;随着信息量的爆炸式增长，用户在选择商品或服务时面临的信息过载问题变得越来越突出。推荐系统是解决这一问题的关键技术，它通过分析用户行为和数据，提供个性化的推荐。目前，基于协同过滤（Collaborative Filtering, CF）的推荐技术是最成功的应用之一，广泛应用于信息过滤和电子商务场景中。&lt;/p&gt;
&lt;p&gt;然而，传统的基于用户的协同过滤方法面临两大挑战：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：随着用户和项目数量的增加，计算开销显著上升，尤其是在处理大量数据时会导致实时推荐变得不可行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐质量&lt;/strong&gt;：数据稀疏性（即用户对大多数项目没有评分）导致推荐的准确性下降。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了解决这些问题，本文提出了基于项目的协同过滤算法。与传统方法相比，基于项目的算法通过分析项目间的相似性来生成推荐，而不是直接寻找相似用户。&lt;/p&gt;
&lt;p&gt;本文探讨了一种新颖的基于项目的协同过滤（Item-Based Collaborative Filtering, IBCF）推荐算法，用于解决传统用户为中心的协同过滤算法在大规模数据集中的性能和推荐质量问题。主要贡献包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;算法分析&lt;/strong&gt;：对项目相似性计算（如余弦相似度、调整余弦相似度和相关性）和推荐生成方法（加权和与回归模型）的深入研究。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;预计算模型&lt;/strong&gt;：提出一种预计算项目相似度的方法，通过静态项目数据提高算法的在线可扩展性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验评估&lt;/strong&gt;：对算法的推荐质量与性能进行了实验比较，结果表明基于项目的算法在推荐精度和效率方面显著优于基于用户的算法。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;主要发现&#34;&gt;主要发现
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;调整余弦相似度在生成高质量推荐方面效果最佳。&lt;/li&gt;
&lt;li&gt;与用户为中心的算法相比，基于项目的算法在数据稀疏性和大规模处理时具有更高的预测精度（较低的平均绝对误差，MAE）。&lt;/li&gt;
&lt;li&gt;通过模型预计算，只需存储少量的相似项目即可生成高质量的推荐，显著提高了系统的响应速度和吞吐量。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;结论&#34;&gt;结论
&lt;/h4&gt;&lt;p&gt;基于项目的协同过滤算法为大规模电子商务中的推荐系统提供了高效且高质量的解决方案，能够在大规模数据集上实现良好的性能表现。这种方法解决了传统用户为中心方法在稀疏性和可扩展性上的瓶颈。&lt;/p&gt;
&lt;h3 id=&#34;原理&#34;&gt;原理
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;基于项目的协同过滤算法&lt;/strong&gt;的核心思想是通过计算项目间的相似性来预测用户对某一项目的偏好。以下是其基本工作流程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://deisbeir.github.io/p/itemcf/2.png&#34;
	width=&#34;1045&#34;
	height=&#34;361&#34;
	srcset=&#34;https://deisbeir.github.io/p/itemcf/2_hu8136991726507575375.png 480w, https://deisbeir.github.io/p/itemcf/2_hu689072321997275323.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250113180530094&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;289&#34;
		data-flex-basis=&#34;694px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;用户-项目评分矩阵&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入为一个矩阵，其中每一行代表一个用户，每一列代表一个项目，矩阵中的值表示用户对项目的评分。&lt;/li&gt;
&lt;li&gt;例如，用户 A 对电影 1 的评分为 5 分，而对电影 2 尚未评分（值为 0）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;项目相似性计算&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;余弦相似度&lt;/strong&gt;：将项目看作向量，计算它们之间夹角的余弦值：&lt;/p&gt;
&lt;img src=&#34;5.png&#34; alt=&#34;image-20250113181156430&#34; style=&#34;zoom: 67%;&#34; /&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;相关性相似度&lt;/strong&gt;：使用皮尔逊相关系数，通过去除用户评分的平均值来计算相似性：&lt;/p&gt;
&lt;img src=&#34;6.png&#34; alt=&#34;image-20250113181311252&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;调整余弦相似度&lt;/strong&gt;：修正余弦相似度，考虑用户评分偏差：&lt;/p&gt;
&lt;img src=&#34;7.png&#34; alt=&#34;image-20250113181354120&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;3.png&#34; alt=&#34;image-20250113180749897&#34;  /&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;评分预测&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;加权和&lt;/strong&gt;：对目标项目的评分预测，利用目标用户对相似项目的评分加权求和：&lt;/p&gt;
&lt;img src=&#34;8.png&#34; alt=&#34;image-20250113181455124&#34; style=&#34;zoom: 80%;&#34; /&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;回归模型&lt;/strong&gt;：利用回归方法对评分进行调整，避免直接使用评分可能产生的误差。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://deisbeir.github.io/p/itemcf/4.png&#34;
	width=&#34;1173&#34;
	height=&#34;419&#34;
	srcset=&#34;https://deisbeir.github.io/p/itemcf/4_hu1753262329743907650.png 480w, https://deisbeir.github.io/p/itemcf/4_hu8124815917033415161.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250113180912486&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;279&#34;
		data-flex-basis=&#34;671px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模型预计算&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对所有项目计算相似性矩阵，只存储每个项目的最相似的几个项目，用于实时推荐。&lt;/li&gt;
&lt;li&gt;通过减少计算范围（即限制 ），显著降低了计算复杂度和存储需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;实验方法&#34;&gt;实验方法
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据集&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用来自 &lt;strong&gt;MovieLens&lt;/strong&gt; 推荐系统的数据集，包含 943 名用户和 1682 部电影，总计约 10 万条评分数据。&lt;/li&gt;
&lt;li&gt;数据被分为训练集和测试集，不同比例（如 80:20）的分割用于实验分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评价指标&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;平均绝对误差（Mean Absolute Error, MAE）&lt;/strong&gt;：衡量预测评分与实际评分之间的平均差异：&lt;/li&gt;
&lt;li&gt;MAE 越低，表示预测精度越高。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验设置&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;对比不同相似性算法（如余弦、调整余弦、相关性）对推荐质量的影响。&lt;/li&gt;
&lt;li&gt;分析训练集比例、邻居数量（ 值）和模型规模对性能和质量的影响。&lt;/li&gt;
&lt;li&gt;与传统用户为中心的  近邻算法进行比较。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;实验结果&#34;&gt;实验结果
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;相似性算法对推荐质量的影响&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;调整余弦相似度的 MAE 最低，优于普通余弦和相关性相似度。&lt;/li&gt;
&lt;li&gt;在所有实验中，调整余弦相似度都被选为推荐算法的默认配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练集比例和邻居数量的敏感性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;随着训练集比例从 20% 增加到 80%，预测质量逐渐提升（MAE 逐渐降低），但收益逐渐减少。&lt;/li&gt;
&lt;li&gt;基于项目的加权和算法在邻居数量  为 30 时达到最佳性能，进一步增加邻居数量提升有限。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;与用户为中心的推荐算法比较&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;基于项目的算法在所有数据稀疏性情况下都优于基于用户的  近邻算法，尤其是在稀疏数据集上表现显著。&lt;/li&gt;
&lt;li&gt;回归模型在极稀疏数据下表现良好，但在高密度数据中可能过拟合，表现反而下降。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型预计算的性能表现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;通过限制模型规模，仅存储最相似的 25-50 个项目，可以实现约 96-98% 的预测精度，显著减少存储和计算时间。&lt;/li&gt;
&lt;li&gt;在处理效率上，基于模型的算法比直接计算的项目-项目方法快 10 倍以上。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结
&lt;/h3&gt;&lt;p&gt;实验表明，基于项目的协同过滤算法不仅在推荐质量上优于传统方法，还在大规模数据集上表现出色。通过预计算技术，算法在计算效率和存储需求之间实现了良好的平衡，是一种适用于电子商务环境的大规模推荐系统解决方案。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Spark</title>
        <link>https://deisbeir.github.io/p/spark/</link>
        <pubDate>Mon, 13 Jan 2025 02:11:08 +0800</pubDate>
        
        <guid>https://deisbeir.github.io/p/spark/</guid>
        <description>&lt;img src="https://deisbeir.github.io/p/spark/show.png" alt="Featured image of post Spark" /&gt;&lt;h3 id=&#34;论文总结spark-cluster-computing-with-working-sets&#34;&gt;论文总结：Spark: Cluster Computing with Working Sets
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://deisbeir.github.io/p/spark/1.png&#34;
	width=&#34;1028&#34;
	height=&#34;183&#34;
	srcset=&#34;https://deisbeir.github.io/p/spark/1_hu4954486465451657638.png 480w, https://deisbeir.github.io/p/spark/1_hu3001456610837097202.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250113022151489&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;561&#34;
		data-flex-basis=&#34;1348px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;​		MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.&lt;/p&gt;
&lt;h4 id=&#34;背景与问题&#34;&gt;背景与问题
&lt;/h4&gt;&lt;p&gt;分布式计算模型，如 MapReduce 和其变体，已经在处理大规模数据密集型应用中取得了显著成功。这些模型利用无环数据流（acyclic data flow）实现并行计算，具有扩展性和容错性。&lt;/p&gt;
&lt;p&gt;然而，这些模型对某些类型的应用支持不足，尤其是需要重复使用数据集的任务，如迭代机器学习算法和交互式数据分析：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;迭代任务&lt;/strong&gt;：许多机器学习算法（如梯度下降）需要对同一数据集进行多次处理。在传统模型中，每次迭代都需要从磁盘重新加载数据，导致性能瓶颈。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;交互式分析&lt;/strong&gt;：在大规模数据集上运行临时查询（如使用 SQL 接口）时，传统模型的高延迟（每次查询需数十秒）限制了交互性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些局限性促使开发一种新的分布式计算框架，以支持高效的迭代和交互式计算，同时保留传统模型的扩展性和容错性。&lt;/p&gt;
&lt;h4 id=&#34;主要贡献&#34;&gt;主要贡献
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;编程模型&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Spark 引入了弹性分布式数据集（Resilient Distributed Datasets, RDDs），这是一个支持容错和内存缓存的分布式数据抽象。&lt;/li&gt;
&lt;li&gt;用户可以通过 RDDs 高效地定义和管理数据流，而无需每次重新加载数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高性能实现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Spark 能够通过缓存和任务优化，将迭代任务的性能提升 10 倍以上。&lt;/li&gt;
&lt;li&gt;提供对大规模数据集的低延迟交互式查询支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;广泛适用性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Spark 框架适用于多种场景，包括迭代机器学习算法、临时数据查询以及复杂的分布式计算任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;模型细节&#34;&gt;模型细节
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;工作流程&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;Spark 的核心是 RDDs，它们是分布在集群上的只读数据集，可以按需重建丢失的分区。&lt;/li&gt;
&lt;li&gt;通过操作如 &lt;code&gt;map&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;reduce&lt;/code&gt;，用户可以轻松定义并行数据流。&lt;/li&gt;
&lt;li&gt;提供内存缓存机制，显著提高了重复操作的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容错机制&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;通过记录 RDD 的 lineage 信息（数据派生关系），Spark 可以在节点失败时重建丢失的数据分区，而无需回滚到检查点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化策略&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;数据本地化：优先在存储数据的节点上运行任务以减少网络传输。&lt;/li&gt;
&lt;li&gt;闭包序列化：支持将用户定义的操作发送到集群节点执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;性能评估&#34;&gt;性能评估
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;实验设置&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;使用亚马逊 EC2 集群进行性能测试，数据集大小为 39GB，集群规模为 15 台机器。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验结果&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;在迭代任务中，Spark 比 Hadoop 快 10 倍，因为后者需要频繁从磁盘加载数据。&lt;/li&gt;
&lt;li&gt;交互式查询的首次响应时间为 35 秒，但后续查询只需 0.5 至 1 秒，提供了与本地数据处理类似的体验。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;应用案例&#34;&gt;应用案例
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;迭代任务&lt;/strong&gt;：如逻辑回归等机器学习算法，通过 RDDs 缓存数据，显著减少了数据加载时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;交互式分析&lt;/strong&gt;：利用 Spark 解释器，可以快速查询大规模数据集，实现高效的交互式数据分析。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;主要优势&#34;&gt;主要优势
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;易用性&lt;/strong&gt;：对开发者友好，隐藏了分布式系统的复杂性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扩展性&lt;/strong&gt;：设计适配大规模集群，轻松处理数十 TB 数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可靠性&lt;/strong&gt;：自动处理节点故障和任务延迟问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效率&lt;/strong&gt;：数据本地化和任务缓存机制减少了网络和计算开销。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;局限性与未来工作&#34;&gt;局限性与未来工作
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;受限于模型的简单性，无法直接处理高度复杂的计算需求。&lt;/li&gt;
&lt;li&gt;后续工作可能包括支持更多的计算模型（如迭代计算）以及提升资源利用率的优化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;总结&#34;&gt;总结
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Spark 通过限制编程模型简化了并行和分布式计算。&lt;/li&gt;
&lt;li&gt;其实现高效可靠，适用于多种实际数据处理场景。&lt;/li&gt;
&lt;li&gt;Spark 已成为大规模数据处理的重要工具，并对分布式计算的发展产生了深远影响。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>MapReduce</title>
        <link>https://deisbeir.github.io/p/mapreduce/</link>
        <pubDate>Sun, 12 Jan 2025 01:31:53 +0800</pubDate>
        
        <guid>https://deisbeir.github.io/p/mapreduce/</guid>
        <description>&lt;img src="https://deisbeir.github.io/p/mapreduce/show.png" alt="Featured image of post MapReduce" /&gt;&lt;h3 id=&#34;论文总结mapreduce-simplified-data-processing-on-large-clusters&#34;&gt;论文总结：MapReduce: Simplified Data Processing on Large Clusters
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://deisbeir.github.io/p/mapreduce/1.png&#34;
	width=&#34;1806&#34;
	height=&#34;880&#34;
	srcset=&#34;https://deisbeir.github.io/p/mapreduce/1_hu9985853499969369981.png 480w, https://deisbeir.github.io/p/mapreduce/1_hu17482999402083861686.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20250113015028959&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;205&#34;
		data-flex-basis=&#34;492px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;背景与问题&#34;&gt;背景与问题
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Google 在处理大规模数据（如网页抓取、日志分析等）时，需要分布式计算技术以高效完成任务。&lt;/li&gt;
&lt;li&gt;传统分布式系统开发复杂，需要手动处理并行化、数据分布和故障恢复，导致代码繁琐且难以维护。&lt;/li&gt;
&lt;li&gt;为解决这些问题，作者提出了 MapReduce 模型，一种简化并行计算的抽象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;主要贡献&#34;&gt;主要贡献
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;编程模型&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;MapReduce 基于两个核心操作：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;map&lt;/code&gt;: 负责从输入中生成中间键值对。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reduce&lt;/code&gt;: 接收共享同一键的所有值，并生成最终结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用户只需实现 &lt;code&gt;map&lt;/code&gt; 和 &lt;code&gt;reduce&lt;/code&gt; 函数，其余复杂操作由系统处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高性能实现&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;采用廉价商品硬件（集群中的数千台 PC）。&lt;/li&gt;
&lt;li&gt;提供自动化的任务分配、数据本地化和容错机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;广泛适用性&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;模型简单，非分布式系统开发人员也能轻松上手。&lt;/li&gt;
&lt;li&gt;适用于数据处理、机器学习、排序等多种任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;模型细节&#34;&gt;模型细节
&lt;/h4&gt;&lt;img src=&#34;2.png&#34; alt=&#34;image-20250113014829473&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;工作流程&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;输入数据分为多个片段（split），每片大小通常为 16-64 MB。&lt;/li&gt;
&lt;li&gt;MapReduce 调度系统负责将任务分配给集群中的计算节点。&lt;/li&gt;
&lt;li&gt;‘Map’ 阶段生成中间键值对；‘Reduce’ 阶段整合这些对。&lt;/li&gt;
&lt;li&gt;最终结果输出到多个文件中。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容错机制&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;如果某个节点失败，未完成的任务会重新分配给其他节点。&lt;/li&gt;
&lt;li&gt;已完成的 ‘map’ 任务需要重新执行，因为中间结果存储在本地磁盘上。&lt;/li&gt;
&lt;li&gt;系统通过任务备份机制解决节点性能瓶颈问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优化策略&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;数据本地化：尽量在存储数据的节点上执行任务以节省网络带宽。&lt;/li&gt;
&lt;li&gt;任务分片（M 和 R 值）：将任务切分为小块以提高并行度和容错能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;性能评估&#34;&gt;性能评估
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;实验设置&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;集群规模：1800 台机器，每台配备双核 CPU、4GB 内存和千兆以太网。&lt;/li&gt;
&lt;li&gt;测试任务：1TB 数据的模式匹配和排序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实验结果&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;模式匹配任务：
&lt;ul&gt;
&lt;li&gt;数据扫描速度峰值达 30 GB/s。&lt;/li&gt;
&lt;li&gt;完成时间约为 150 秒，其中 1 分钟为启动开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;排序任务：
&lt;ul&gt;
&lt;li&gt;输入速率峰值 13 GB/s，受限于中间数据写入磁盘的开销。&lt;/li&gt;
&lt;li&gt;备份机制启用后，执行时间缩短 44%。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;应用案例&#34;&gt;应用案例
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Google 内部使用&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;搜索引擎索引的构建。&lt;/li&gt;
&lt;li&gt;数据挖掘与统计分析（如 Google Zeitgeist 和 Google Trends）。&lt;/li&gt;
&lt;li&gt;大规模机器学习和图处理任务。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;规模增长&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;从 2003 年到 2006 年，MapReduce 的应用从数百扩展到数千个程序，每天处理超过 20PB 数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;主要优势&#34;&gt;主要优势
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;易用性&lt;/strong&gt;：对开发者友好，隐藏了分布式系统的复杂性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扩展性&lt;/strong&gt;：设计适配大规模集群，轻松处理数十 PB 数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可靠性&lt;/strong&gt;：自动处理节点故障和任务延迟问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效率&lt;/strong&gt;：数据本地化和任务备份机制减少了网络和计算开销。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;局限性与未来工作&#34;&gt;局限性与未来工作
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;受限于模型的简单性，无法直接处理高度复杂的计算需求。&lt;/li&gt;
&lt;li&gt;后续工作可能包括支持更多的计算模型（如迭代计算）以及提升资源利用率的优化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;总结&#34;&gt;总结
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;MapReduce 通过限制编程模型简化了并行和分布式计算。&lt;/li&gt;
&lt;li&gt;其实现高效可靠，适用于多种实际数据处理场景。&lt;/li&gt;
&lt;li&gt;MapReduce 已成为 Google 内部大规模数据处理的核心工具，并对分布式计算的发展产生了深远影响。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
