[{"content":"MySQL索引 索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。\n索引底层数据结构存在很多种类型，常见的索引结构有: B 树， B+树 和 Hash、红黑树。在 MySQL 中，无论是 Innodb 还是 MyIsam，都使用了 B+树作为索引结构。\n二叉查找树(BST) 二叉查找树（Binary Search Tree）是一种基于二叉树的数据结构，它具有以下特点：\n左子树所有节点的值均小于根节点的值。 右子树所有节点的值均大于根节点的值。 左右子树也分别为二叉查找树。 当二叉查找树是平衡的时候，也就是树的每个节点的左右子树深度相差不超过 1 的时候，查询的时间复杂度为 O(log2(N))，具有比较高的效率。然而，当二叉查找树不平衡时，例如在最坏情况下（有序插入节点），树会退化成线性链表（也被称为斜树），导致查询效率急剧下降，时间复杂退化为 O（N）。\n也就是说，二叉查找树的性能非常依赖于它的平衡程度，这就导致其不适合作为 MySQL 底层索引的数据结构。\n为了解决这个问题，并提高查询效率，人们发明了多种在二叉查找树基础上的改进型数据结构，如平衡二叉树、B-Tree、B+Tree 等。\nAVL 树 AVL 树是计算机科学中最早被发明的自平衡二叉查找树，它的名称来自于发明者 G.M. Adelson-Velsky 和 E.M. Landis 的名字缩写。AVL 树的特点是保证任何节点的左右子树高度之差不超过 1，因此也被称为高度平衡二叉树，它的查找、插入和删除在平均和最坏情况下的时间复杂度都是 O(logn)。\nAVL 树采用了旋转操作来保持平衡。主要有四种旋转操作：LL 旋转、RR 旋转、LR 旋转和 RL 旋转。其中 LL 旋转和 RR 旋转分别用于处理左左和右右失衡，而 LR 旋转和 RL 旋转则用于处理左右和右左失衡。\n由于 AVL 树需要频繁地进行旋转操作来保持平衡，因此会有较大的计算开销进而降低了数据库写操作的性能。并且， 在使用 AVL 树时，每个树节点仅存储一个数据，而每次进行磁盘 IO 时只能读取一个节点的数据，如果需要查询的数据分布在多个节点上，那么就需要进行多次磁盘 IO。 磁盘 IO 是一项耗时的操作，在设计数据库索引时，我们需要优先考虑如何最大限度地减少磁盘 IO 操作的次数。\n红黑树 红黑树是一种自平衡二叉查找树，通过在插入和删除节点时进行颜色变换和旋转操作，使得树始终保持平衡状态，它具有以下特点：\n每个节点非红即黑； 根节点总是黑色的； 每个叶子节点都是黑色的空节点（NIL 节点）； 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）； 从任意节点到它的叶子节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。 和 AVL 树不同的是，红黑树并不追求严格的平衡，而是大致的平衡。正因如此，红黑树的查询效率稍有下降，因为红黑树的平衡性相对较弱，可能会导致树的高度较高，这可能会导致一些数据需要进行多次磁盘 IO 操作才能查询到，这也是 MySQL 没有选择红黑树的主要原因。也正因如此，红黑树的插入和删除操作效率大大提高了，因为红黑树在插入和删除节点时只需进行 O(1) 次数的旋转和变色操作，即可保持基本平衡状态，而不需要像 AVL 树一样进行 O(logn) 次数的旋转操作。\n红黑树的应用还是比较广泛的，TreeMap、TreeSet 以及 JDK1.8 的 HashMap 底层都用到了红黑树。对于数据在内存中的这种情况来说，红黑树的表现是非常优异的。\nB 树 B 树全称为 多路平衡查找树 。\n在 B 树中，有两种节点：\n内部节点（internal node）：存储了数据以及指向其子节点的指针。 叶子节点（leaf node）：与内部节点不同的是，叶子节点只存储数据，并没有子节点。 m阶的 B 树的特性\n​\t表示这个树的每一个节点最多可以拥有的子节点个数。一棵m阶的 B 树满足的性质如下：\n每个节点最多有m个子节点。 每一个非叶子节点（除根节点）最少有 $\\frac{m}{2}$ 个子节点。 如果根节点不是叶子节点，那么它至少有两个子节点。 有K个子节点的非叶子节点拥有k-1个键，且升序排列，满足k[i]\u0026lt;k[i+1]。 所有的叶子节点都在同一层。 B 树优势 之前已经介绍过二叉查找树。但是这类型数据结构的问题在于，由于每个节点只能容纳一个数据，导致树的高度很高，逻辑上挨着的节点数据可能离得很远。\n考虑在磁盘中存储数据的情况，与内存相比，读写磁盘有以下不同点：\n读写磁盘的速度相比内存读写慢很多。 每次读写磁盘的单位要比读写内存的最小单位大很多。 由于读写磁盘的这个特点，因此对应的数据结构应该尽量的满足「局部性原理」：「当一个数据被用到时，其附近的数据也通常会马上被使用」，为了满足局部性原理，所以应该将逻辑上相邻的数据在物理上也尽量存储在一起。这样才能减少读写磁盘的数量。\n所以，对比起一个节点只能存储一个数据的 BST 类数据结构来，要求这种数据结构在形状上更「胖」、更加「扁平」，即：每个节点能容纳更多的数据，这样就能降低树的高度，同时让逻辑上相邻的数据都能尽量存储在物理上也相邻的硬盘空间上，减少磁盘读写。\nB+树 B+ 树是 B 树 的一个升级，它比 B 树更适合实际应用中操作系统的文件索引和数据库索引。\nB+ 树是一种多叉排序树，即每个节点通常有多个孩子。一棵 B+ 树包含根节点、内部节点和叶子节点。根节点可能是一个叶子节点，也可能是一个包含两个或两个以上孩子节点的节点。\nB+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反。\nm阶 B+ 树的特性\n​\tm表示这个树的每一个节点最多可以拥有的子节点个数。一棵m阶的 B+ 树和 B 树的差异在于：\n有n棵子树的节点中含有n-1个关键字（即将区间分为n个子区间，每个子区间对应一棵子树)。 所有叶子节点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子节点本身依关键字的大小自小而大顺序链接。 所有的非叶子节点可以看成是索引部分，节点中仅含有其子树（根节点）中的最大（或最小）关键字。 除根节点外，其他所有节点中所含关键字的个数最少有 $\\frac{m}{2}$（注意：B 树中除根以外的所有非叶子节点至少有$\\frac{m}{2}$棵子树)。 同时，B+ 树为了方便范围查询，叶子节点之间还用指针串联起来。\nB+ 树相比于 B 树的优势 由于索引节点上只有索引而没有数据，所以索引节点上能存储比 B 树更多的索引，这样树的高度就会更矮。树的高度越矮，磁盘寻道的次数就会越少。\n因为数据都集中在叶子节点，而所有叶子节点的高度相同，那么可以在叶子节点中增加前后指针，指向同一个父节点的相邻兄弟节点，这样可以更好地支持查询一个值的前驱或后继，使连续访问更容易实现。\n比如这样的 SQL 语句：select * from tbl where t \u0026gt; 10，如果使用 B+ 树存储数据的话，可以首先定位到数据为 10 的节点，再沿着它的 next 指针一路找到所有在该叶子节点右边的叶子节点，返回这些节点包含的数据。\n主键索引(Primary Key) 数据表的主键列使用的就是主键索引。\n一张数据表有只能有一个主键，并且主键不能为 null，不能重复。\n在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在 null 值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。\n二级索引 二级索引（Secondary Index）的叶子节点存储的数据是主键的值，也就是说，通过二级索引可以定位主键的位置，二级索引又称为辅助索引/非主键索引。\n唯一索引，普通索引，前缀索引等索引都属于二级索引。\n唯一索引(Unique Key):唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。 普通索引(Index):普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。 前缀索引(Prefix):前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小，因为只取前几个字符。 全文索引(Full Text):全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。 覆盖索引 如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为 覆盖索引（Covering Index） 。\n在 InnoDB 存储引擎中，非主键索引的叶子节点包含的是主键的值。这意味着，当使用非主键索引进行查询时，数据库会先找到对应的主键值，然后再通过主键索引来定位和检索完整的行数据。这个过程被称为“回表”。\n覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询\n联合索引 使用表中的多个字段创建索引，就是 联合索引，也叫 组合索引 或 复合索引。\n最左前缀匹配原则 最左前缀匹配原则指的是在使用联合索引时，MySQL 会根据索引中的字段顺序，从左到右依次匹配查询条件中的字段。如果查询条件与索引中的最左侧字段相匹配，那么 MySQL 就会使用索引来过滤数据，这样可以提高查询效率。\n最左匹配原则会一直向右匹配，直到遇到范围查询（如 \u0026gt;、\u0026lt;）为止。\n顺序的重要性： 复合索引的列顺序非常重要，查询条件必须从最左列开始匹配。 例如，索引 (name, age) 不能用于查询 WHERE age = 30。 范围查询的影响： 范围查询会中断索引的匹配，其右边的列不会被索引使用。 例如，索引 (name, age, email) 在查询 WHERE name = 'John' AND age \u0026gt; 30 AND email = 'test@example.com' 中，只有 name 和 age 列会被索引使用，email 列不会被索引使用。 覆盖索引： 如果查询的列都包含在复合索引中，MySQL 可以直接从索引中获取数据，而无需回表。 例如，索引 (name, age) 可以用于查询 SELECT name, age FROM users WHERE name = 'John'。 索引下推 索引下推（Index Condition Pushdown，简称 ICP） 是 MySQL 5.6 版本中提供的一项索引优化功能，它允许存储引擎在索引遍历过程中，执行部分 WHERE字句的判断条件，直接过滤掉不满足条件的记录，从而减少回表次数，提高查询效率。\nMySQL 可以简单分为 Server 层和存储引擎层这两层。Server 层处理查询解析、分析、优化、缓存以及与客户端的交互等操作，而存储引擎层负责数据的存储和读取，MySQL 支持 InnoDB、MyISAM、Memory 等多种存储引擎。\n索引下推的下推其实就是指将部分上层（Server 层）负责的事情，交给了下层（存储引擎层）去处理。\n在传统的查询执行过程中，存储引擎会根据索引查找数据，然后将所有匹配索引条件的数据返回到服务器层，服务器层再根据其他条件进行过滤。而索引下推则允许存储引擎在索引查找阶段直接应用部分查询条件，从而减少返回给服务器层的数据量。\n示例 假设有一个表 users，结构如下：\n1 2 3 4 5 6 CREATE TABLE users ( id INT PRIMARY KEY, name VARCHAR(100), age INT, email VARCHAR(100) ); 在 name 和 age 列上创建复合索引：\n1 CREATE INDEX idx_name_age ON users(name, age); 执行以下查询：\n1 SELECT * FROM users WHERE name = \u0026#39;John\u0026#39; AND age \u0026gt; 30; 传统查询过程 存储引擎使用索引 idx_name_age 查找 name = 'John' 的所有数据。 将所有 name = 'John' 的数据返回到服务器层。 服务器层根据 age \u0026gt; 30 进行过滤。 索引下推查询过程 存储引擎使用索引 idx_name_age 查找 name = 'John' 的数据。 在索引查找阶段，直接应用 age \u0026gt; 30 的条件，过滤掉不符合条件的数据。 只将 name = 'John' 且 age \u0026gt; 30 的数据返回到服务器层。 索引下推的优势 可以减少回表次数之外，索引下推还可以减少存储引擎层和 Server 层的数据传输量。 适用于执行计划是 range, ref, eq_ref, ref_or_null 的范围查询。 对于 InnoDB 表，仅用于非聚簇索引。索引下推的目标是减少全行读取次数，从而减少 I/O 操作。对于 InnoDB 聚集索引，完整的记录已经读入 InnoDB 缓冲区。在这种情况下使用索引下推 不会减少 I/O。 子查询不能使用索引下推，因为子查询通常会创建临时表来处理结果，而这些临时表是没有索引的。 存储过程不能使用索引下推，因为存储引擎无法调用存储函数。 ","date":"2024-12-31T16:36:08+08:00","image":"https://deisbeir.github.io/p/mysql%E7%B4%A2%E5%BC%95/show_hu14899049146289445645.png","permalink":"https://deisbeir.github.io/p/mysql%E7%B4%A2%E5%BC%95/","title":"MySQL索引"},{"content":"什么是关系型数据库？ 顾名思义，关系型数据库（RDB，Relational Database）就是一种建立在关系模型的基础上的数据库。关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。\nMySQL 字段类型 MySQL 字段类型可以简单分为三大类：\n数值类型：整型（TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT）、浮点型（FLOAT 和 DOUBLE）、定点型（DECIMAL） 字符串类型：CHAR、VARCHAR、TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT、TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB 等，最常用的是 CHAR 和 VARCHAR。 日期时间类型：YEAR、TIME、DATE、DATETIME 和 TIMESTAMP 等。 MySQL 索引 MySQL 查询缓存 MySQL 查询缓存是查询结果缓存。执行查询语句的时候，会先查询缓存，如果缓存中有对应的查询结果，就会直接返回。\n查询缓存会在同样的查询条件和数据情况下，直接返回缓存中的结果。但需要注意的是，查询缓存的匹配条件非常严格，任何细微的差异都会导致缓存无法命中。这里的查询条件包括查询语句本身、当前使用的数据库、以及其他可能影响结果的因素，如客户端协议版本号等。\n查询缓存不命中的情况：\n任何两个查询在任何字符上的不同都会导致缓存不命中。 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL 库中的系统表，其查询结果也不会被缓存。 缓存建立之后，MySQL 的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。 缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。\nMySQL 事务 何谓事务？ 事务是逻辑上的一组操作，要么都执行，要么都不执行。\n何谓数据库事务？ 大多数情况下，我们在谈论事务的时候，如果没有特指分布式事务，往往指的就是数据库事务。\n数据库事务在我们日常开发中接触的最多了。如果你的项目属于单体架构的话，你接触到的往往就是数据库事务了。\n数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：要么全部执行成功,要么全部不执行 。\n1 2 3 4 5 6 # 开启一个事务 START TRANSACTION; # 多条 SQL 语句 SQL1,SQL2... ## 提交事务 COMMIT; 另外，关系型数据库（例如：MySQL、SQL Server、Oracle 等）事务都有 ACID 特性：\n原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；\n一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；\n隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；\n持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。\n只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！\n并发事务带来了哪些问题? 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。\n脏读（Dirty read） 一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚，导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据，这也就是脏读的由来。\n丢失修改（Lost to modify） 在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。\n不可重复读（Unrepeatable read） 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。\n幻读（Phantom read） 幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。\n不可重复读和幻读有什么区别？ 不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把幻读区分出来的原因主要是解决幻读和不可重复读的方案不一样。\n并发事务的控制方式有哪些？ MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。锁可以看作是悲观控制的模式，多版本并发控制（MVCC，Multiversion concurrency control）可以看作是乐观控制的模式。\n锁 控制方式下会通过锁来显式控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。\n共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。 读写锁可以做到读读并行，但是无法做到写读、写写并行。另外，根据根据锁粒度的不同，又被分为 表级锁(table-level locking) 和 行级锁(row-level locking) 。InnoDB 不光支持表级锁，还支持行级锁，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。\nMVCC 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。\nMVCC 在 MySQL 中实现所依赖的手段主要是: 隐藏字段、read view、undo log。\nundo log : undo log 用于记录某行数据的多个版本的数据。 read view 和 隐藏字段 : 用来判断当前版本数据的可见性。 SQL 标准定义了哪些事务隔离级别? SQL 标准定义了四个隔离级别：\nREAD-UNCOMMITTED(读取未提交) ：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交) ：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读) ：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化) ：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × MySQL 的隔离级别是基于锁实现的吗？ MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。\nSERIALIZABLE 隔离级别是通过锁来实现的，READ-COMMITTED 和 REPEATABLE-READ 隔离级别是基于 MVCC 实现的。不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。\nMySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。\nMySQL 性能怎么优化？ 1. 抓住核心：慢 SQL 定位与分析\n性能优化的第一步永远是找到瓶颈。\n监控工具： 介绍常用的慢 SQL 监控工具，如 MySQL 慢查询日志、Performance Schema 等，说明你对这些工具的熟悉程度以及如何通过它们定位问题。 EXPLAIN 命令： 详细说明 EXPLAIN 命令的使用，分析查询计划、索引使用情况，可以结合实际案例展示如何解读分析结果，比如执行顺序、索引使用情况、全表扫描等。 2. 由点及面：索引、表结构和 SQL 优化\n定位到慢 SQL 后，接下来就要针对具体问题进行优化。 这里可以重点介绍索引、表结构和 SQL 编写规范等方面的优化技巧：\n索引优化： 这是 MySQL 性能优化的重点，可以介绍索引的创建原则、覆盖索引、最左前缀匹配原则等。如果能结合你项目的实际应用来说明如何选择合适的索引，会更加分一些。 表结构优化： 优化表结构设计，包括选择合适的字段类型、避免冗余字段、合理使用范式和反范式设计等等。 SQL 优化： 避免使用 SELECT *、尽量使用具体字段、使用连接查询代替子查询、合理使用分页查询、批量操作等，都是 SQL 编写过程中需要注意的细节。 3. 进阶方案：架构优化\n当面试官对基础优化知识比较满意时，可能会深入探讨一些架构层面的优化方案。以下是一些常见的架构优化策略：\n读写分离： 将读操作和写操作分离到不同的数据库实例，提升数据库的并发处理能力。 分库分表： 将数据分散到多个数据库实例或数据表中，降低单表数据量，提升查询效率。但要权衡其带来的复杂性和维护成本，谨慎使用。 数据冷热分离：根据数据的访问频率和业务重要性，将数据分为冷数据和热数据，冷数据一般存储在存储在低成本、低性能的介质中，热数据高性能存储介质中。 缓存机制： 使用 Redis 等缓存中间件，将热点数据缓存到内存中，减轻数据库压力。这个非常常用，提升效果非常明显，性价比极高！ 4. 其他优化手段\n除了慢 SQL 定位、索引优化和架构优化，还可以提及一些其他优化手段，展示你对 MySQL 性能调优的全面理解：\n连接池配置： 配置合理的数据库连接池（如 连接池大小、超时时间 等），能够有效提升数据库连接的效率，避免频繁的连接开销。\n硬件配置： 提升硬件性能也是优化的重要手段之一。使用高性能服务器、增加内存、使用 SSD 硬盘等硬件升级，都可以有效提升数据库的整体性能。\n读写分离： 将读操作和写操作分离到不同的数据库实例，提升数据库的并发处理能力。\n分库分表： 将数据分散到多个数据库实例或数据表中，降低单表数据量，提升查询效率。但要权衡其带来的复杂性和维护成本，谨慎使用。\n数据冷热分离：根据数据的访问频率和业务重要性，将数据分为冷数据和热数据，冷数据一般存储在存储在低成本、低性能的介质中，热数据高性能存储介质中。\n缓存机制： 使用 Redis 等缓存中间件，将热点数据缓存到内存中，减轻数据库压力。这个非常常用，提升效果非常明显，性价比极高！\n4. 其他优化手段\n除了慢 SQL 定位、索引优化和架构优化，还可以提及一些其他优化手段，展示你对 MySQL 性能调优的全面理解：\n连接池配置： 配置合理的数据库连接池（如 连接池大小、超时时间 等），能够有效提升数据库连接的效率，避免频繁的连接开销。 硬件配置： 提升硬件性能也是优化的重要手段之一。使用高性能服务器、增加内存、使用 SSD 硬盘等硬件升级，都可以有效提升数据库的整体性能。 本文内容基本来自JavaGuide\n","date":"2024-12-30T15:46:45+08:00","image":"https://deisbeir.github.io/p/mysql/show_hu15893453219600356970.png","permalink":"https://deisbeir.github.io/p/mysql/","title":"MySQL"},{"content":"ES分布式搜索引擎 什么是elasticsearch？ 一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能 什么是elastic stack（ELK）？ 是以elasticsearch为核心的技术栈，包括beats、Logstash、kibana、elasticsearch 什么是Lucene？ 是Apache的开源搜索引擎类库，提供了搜索引擎的核心API ES核心特性 分布式架构： 数据自动分片（Sharding）和复制（Replication），支持水平扩展。 高可用性，即使部分节点故障，系统仍能正常运行。 实时搜索： 数据几乎可以实时被搜索和分析。 支持复杂的查询和聚合操作。 全文搜索： 基于 Lucene 的全文搜索引擎，支持多语言分词、模糊搜索、短语搜索等。 多数据类型支持： 支持结构化、非结构化和半结构化数据。 支持 JSON 文档存储。 强大的查询语言： 提供丰富的查询 DSL（Domain Specific Language），支持复杂查询和过滤。 聚合分析： 支持对数据进行统计、分析和可视化（如平均值、求和、分组等）。 RESTful API： 通过 HTTP 接口进行操作，易于集成和使用。 与 ELK Stack 集成： 通常与 Logstash（数据收集和处理）和 Kibana（数据可视化）一起使用，构成 ELK Stack。 ES核心概念 Index（索引）： 类似于数据库中的表，用于存储具有相似结构的文档。 例如，user 索引可以存储用户相关的文档。 Document（文档）： 索引中的基本数据单元，以 JSON 格式存储。 例如，一个用户文档可能包含 id、name、age 等字段。 Type（类型）： 在 Elasticsearch 7.x 之前，索引可以包含多个类型（类似于表的分区）。 从 Elasticsearch 7.x 开始，类型被弃用，每个索引只能包含一个类型（_doc）。 Shard（分片）： 索引被分成多个分片，分布在不同的节点上，以实现水平扩展。 分为主分片（Primary Shard）和副本分片（Replica Shard）。 Node（节点）： Elasticsearch 集群中的一个实例，负责存储数据和执行操作。 Cluster（集群）： 由一个或多个节点组成，共同存储和操作数据。 Mapping（映射）： 定义索引中文档的字段类型和属性（如字符串、数值、日期等）。 Query DSL（查询语言）： 用于定义搜索和过滤条件的 JSON 格式语言。 基本操作示例 1. 创建索引 1 2 3 4 5 6 7 8 9 10 11 12 13 14 PUT /user { \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 3, \u0026#34;number_of_replicas\u0026#34;: 1 }, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } } 2. 添加文档 1 2 3 4 5 6 POST /user/_doc/1 { \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;age\u0026#34;: 30, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34; } 3. 搜索文档 1 2 3 4 5 6 7 8 GET /user/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;John\u0026#34; } } } 4. 聚合分析 1 2 3 4 5 6 7 8 GET /user/_search { \u0026#34;aggs\u0026#34;: { \u0026#34;avg_age\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; } } } } ","date":"2024-12-23T15:20:30+08:00","image":"https://deisbeir.github.io/p/elasticsearch%E8%AE%B0%E5%BD%95/show_hu7763026701606020326.png","permalink":"https://deisbeir.github.io/p/elasticsearch%E8%AE%B0%E5%BD%95/","title":"Elasticsearch记录"},{"content":"一、MQ相关的概念 1、MQ的基本概念 什么是MQ MQ(message queue)，从字面意思上看就个 FIFO 先入先出的队列，只不过队列中存放的内容是 message 而已，它是一种具有接收数据、存储数据、发送数据等功能的技术服务。\n在互联网架构中，MQ 是一种非常常见的上下游“逻辑解耦+物理解耦”的消息通信服务，用于上下游传递消息。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不用依赖其他服务\n为什么要用MQ 高并发的流量削峰\n问题：在高并发场景下，系统可能无法处理突发的请求，导致服务崩溃或响应变慢。 解决方案：消息队列可以作为缓冲区，将请求暂存起来，消费者按照自己的处理能力逐步消费。 好处：平滑流量峰值，避免系统过载，提高系统的稳定性。 应用解耦\n问题：在紧耦合的系统中，一个组件的变更可能会影响其他组件，导致系统难以维护和扩展。 解决方案：消息队列允许生产者和消费者通过异步通信解耦，生产者只需将消息发送到队列，而不需要知道消费者的具体实现。 好处：系统组件可以独立开发、部署和扩展，降低复杂性。 异步通信\n问题：同步通信（如 HTTP 请求）会导致调用方阻塞，直到被调用方完成处理，影响系统性能。 解决方案：消息队列支持异步通信，生产者发送消息后可以立即返回，消费者在合适的时候处理消息。 好处：提高系统的响应速度和吞吐量，尤其适合处理耗时任务（如发送邮件、生成报表等）。 分布式事务\n问题：在分布式系统中，不同服务可能部署在不同的节点上，直接通信可能复杂且低效。 解决方案：消息队列作为中间件，提供统一的通信机制，简化分布式系统的设计和实现。 好处：支持跨语言、跨平台通信，方便构建分布式架构。 数据分发\n问题：单个消费者可能无法处理大量任务，导致性能瓶颈。 解决方案：消息队列可以将任务分发给多个消费者，实现负载均衡。 好处：充分利用系统资源，提高任务处理效率。 2.消息队列协议 1. AMQP（Advanced Message Queuing Protocol） 提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。\n特点： 开放标准的消息协议，支持跨平台和跨语言。 提供丰富的消息模式（如点对点、发布/订阅）。 支持事务、消息确认和持久化。 优点： 灵活、可靠，适合复杂的消息通信场景。 2. MQTT（Message Queuing Telemetry Transport） 它是一种基于发布/订阅（publish/subscribe）模式的\u0026quot;轻量级\u0026quot;通讯协议，该协议构建于TCP/IP协议上.\n特点： 轻量级的发布/订阅协议，专为低带宽、不稳定的网络设计。 支持三种消息传递质量（QoS）：最多一次、至少一次、恰好一次。 适合物联网（IoT）场景。 优点： 简单、高效，适合资源受限的设备。 3. Kafka Protocol 基于TCP/IP的二进制协议。消息内部是通过长度来分割，由些基本数据类型组成。\n特点： 专为高吞吐量、分布式流处理设计。 基于二进制协议，性能高效。 支持持久化日志和流式处理。 优点： 高吞吐量、低延迟，适合大数据和实时处理场景。 3.消息队列持久化 持久化简单来说就是将数据存入磁盘，而不是存在内存中随服务器重启断开而消失，使数据能够永久保存。\n4.消息的分发策略 1. 发布/订阅（Publish/Subscribe） 特点： 消息发送到一个主题（Topic）中，所有订阅该主题的消费者都会收到消息。 消息会被广播给多个消费者。 适用场景： 事件通知、日志广播等需要消息被多个消费者处理的场景。 2. 轮询分发（Round Robin） 特点： 消息依次分发给多个消费者，确保每个消费者处理的消息数量大致相同。 适用场景： 负载均衡，适用于消费者处理能力相近的场景。 3. 延迟分发（Delayed Dispatch） 特点： 消息在指定的延迟时间后被分发给消费者。 适用场景： 定时任务、重试机制等需要延迟处理的场景。 4. 公平分发（Fair Dispatch） 特点： 根据消费者的处理能力动态分发消息，避免某些消费者过载。 只有在消费者确认处理完当前消息后，才会接收下一条消息。 适用场景： 消费者处理能力不均衡的场景。 二、RabbitMQ 1.RabbitMQ的概念 RabbitMQ 是一个消息中间件：它接受并转发消息。可以把它当做一个快递站点，当你要发送一个包裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是一个快递站，一个快递员帮你传递快件。RabbitMQ 接收，存储和转发消息数据。\n2. AMQP协议 RabbitMQ是一种遵循AMQP协议的分布式消息中间件。AMQP 全称 “Advanced Message Queuing Protocol”，高级消息队列协议。它是应用层协议的一个开发标准，为面向消息的中间件设计。\n下图是采用 AMQP 协议的生产者和消费者建立和释放连接的流程图：\n3. RabbitMQ架构组成 Broker : 标识消息队列服务器实体rabbitmq-server\nv-host : Virtual Host 虚拟主机。标识一批交换机、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个vhost本质上就是一个mini版的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在链接时指定，RabbitMQ默认的vhost是 /。\nExchange: 交换器用来接收生产者发送的消息并将这些消息路由给服务器中的队列。\nQueue : 消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。\nBanding : 绑定，用于消息队列和交换机之间的关联。一个绑定就是基于路由键将交换机和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。\nChannel : 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟链接，AMQP命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说，建立和销毁TCP都是非常昂贵的开销，所以引入了信道的概念，以复用一条TCP连接。\nConnection : 网络连接，比如一个TCP连接。\n4. 四大核心概念 生产者：产生数据发送消息的程序是生产者。\n交换机：交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个是由交换机类型决定的。\n队列：队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。\n消费者：消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。\n","date":"2024-12-19T23:39:10+08:00","image":"https://deisbeir.github.io/p/rabbitmq%E7%9F%A5%E8%AF%86%E7%82%B9/show_hu1012737271342934363.png","permalink":"https://deisbeir.github.io/p/rabbitmq%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"RabbitMQ知识点"},{"content":"Redis 相关内容记录 Redis 是一个高性能的内存数据存储系统，广泛应用于缓存、消息队列、实时分析等领域。\n1. 内存存储机制 Redis 的数据存储在内存中，这意味着数据访问速度非常快。然而，内存存储也带来了数据持久化的问题。\n2. 数据结构 Redis 支持多种数据结构，每种都有其独特的实现和适用场景：\n字符串（String）：Redis 的基本数据类型，支持动态字符串和原子操作，适用于存储简单键值对。 哈希（Hash）：由键值对组成的集合，内部使用哈希表实现，适合存储对象的多个字段。 列表（List）：有序的字符串集合，使用双向链表实现，适合在两端进行高效插入和删除操作。 集合（Set）：无序的唯一字符串集合，内部使用哈希表实现，支持高效的成员检查和集合运算。 有序集合（Sorted Set）：集合的扩展，每个成员关联一个分数，使用哈希表和跳表实现，支持有序操作。 位图（Bitmap）：通过位操作在字符串上实现，适用于存储大量的布尔值，非常节省内存。 HyperLogLog：一种概率数据结构，用于估计集合中唯一元素的数量，适用于大数据量的统计场景。 地理空间索引（Geospatial Index）：使用有序集合和 geohash 实现，支持高效的地理范围查询。 3. 内存管理 Redis 使用 slab 分配器管理内存，减少内存碎片并提高缓存局部性。数据淘汰策略如 LRU、TTL 和随机淘汰，帮助管理内存使用。\n4. 持久化 Redis 提供了两种持久化机制：RDB（快照持久化）和 AOF（日志持久化），它们各自有不同的工作原理和适用场景。以下是对这两种机制的详细解析：\n4.1. RDB (Redis Database Backup) RDB 快照：定期将内存中的数据快照保存到磁盘，形成一个 RDB 文件。\n工作原理: RDB 通过 fork 一个子进程来生成数据快照，并将快照保存到磁盘。主进程在此期间继续处理请求，不会被阻塞。 配置: 通过 save 指令配置快照策略，例如 save 900 1 表示在900秒内有1次修改时进行保存。 性能考虑: 使用写时复制（Copy-On-Write）技术，避免内存复制开销，确保主进程性能不受影响。 优缺点: 优点是文件紧凑，适合快速恢复；缺点是可能会丢失最近修改的数据。 4.2. AOF (Append Only File) AOF 日志：记录每一个写操作，确保数据的持久化。\n工作原理: AOF 通过追加日志文件记录每一次写操作，恢复时重新执行这些操作。 配置: 通过 appendfsync 选项控制同步频率，有 always、everysec 和 no 三个可选值。 文件重写: 定期重写 AOF 文件，生成只包含恢复数据所需最小操作的文件，减少文件大小。 优缺点: 优点是数据安全性高，缺点是文件较大且恢复速度较慢。 4.3. RDB 与 AOF 的结合使用 优先级: Redis 启动时优先加载 AOF 文件，若 AOF 文件不可用，则加载 RDB 文件。 数据一致性: 两者独立进行，但 Redis 会自动处理潜在的一致性问题。 4.4. 持久化与性能 影响: 过于频繁的持久化操作可能影响性能，需根据实际场景调整策略。 优化: 可通过调整配置或优化硬件（如使用更快的磁盘）来缓解性能压力。 5. Redis 高可用架构设计 Redis 的高可用性架构设计旨在确保系统在故障发生时仍能继续提供服务，通常通过复制、监控和自动故障转移机制来实现。\n5.1. 主从复制（Master-Slave Replication） 基本原理： 主节点（Master）处理读写请求，从节点（Slave）复制主节点的数据。 从节点可以提供读扩展和数据冗余。 故障转移： 手动故障转移：手动将从节点升级为主节点。 自动故障转移：结合 Sentinel 实现自动故障检测和转移。 配置： slaveof 命令配置从节点。 replica-serve-stale-data 控制从节点在连接不上主节点时的行为。 5.2. Sentinel（监控与自动故障转移） 功能： 监控 Redis 实例的状态（主从节点）。 检测故障并自动进行故障转移。 通知客户端主节点变更。 配置： 配置 Sentinel 节点，指定监控的主节点和从节点。 设置 quorum 决定多少 Sentinel 节点同意才能进行故障转移。 down-after-milliseconds 等参数调整故障检测的敏感度。 工作流程： Sentinel 定期检查 Redis 实例的心跳。 当主节点故障时， Sentinel 选举一个从节点升级为主节点。 其他从节点重新配置指向新的主节点。 5.3. Redis Cluster（集群模式） 高可用性： 自动分片，数据分布在多个节点。 每个节点有多个副本（从节点），支持自动故障转移。 数据分片： 数据根据键的哈希值分布到 16384 个槽中。 每个槽由一个主节点负责，可配置多个从节点。 故障转移： 当主节点故障时，集群自动选择一个从节点升级为主节点。 客户端需支持集群模式，以处理槽的重新分配。 配置与管理： 使用 redis-cli --cluster 命令进行集群的创建和管理。 配置 cluster-node-timeout 等参数调整集群行为。 6.Redis 缓存击穿、缓存雪崩、缓存穿透 在高并发场景下，缓存系统（如 Redis）可能会遇到缓存击穿、缓存雪崩和缓存穿透等问题。这些问题会导致数据库压力骤增，甚至引发系统崩溃。\n对比 问题 定义 原因 解决方案 缓存击穿 热点数据失效，大量请求直接访问数据库。 热点数据过期或缓存未命中。 加锁、永不过期、热点数据预热。 缓存雪崩 大量缓存数据同时失效，导致数据库压力骤增。 缓存数据设置相同过期时间或 Redis 宕机。 分散过期时间、多级缓存、高可用架构、限流与降级。 缓存穿透 查询不存在的数据，缓存和数据库均未命中，导致每次请求都访问数据库。 恶意请求或非法查询。 缓存空值、布隆过滤器、参数校验。 最佳实践 合理设置缓存过期时间： 避免缓存集中失效，设置随机过期时间。 监控与报警： 实时监控缓存命中率和数据库查询量，及时发现异常。 限流与降级： 在缓存失效时，通过限流和降级保护数据库。 数据预热： 提前加载热点数据到缓存中，避免冷启动问题。 使用布隆过滤器： 对于可能不存在的数据，使用布隆过滤器减少无效查询。 ","date":"2024-12-17T23:39:10+08:00","image":"https://deisbeir.github.io/p/redis-%E7%9F%A5%E8%AF%86%E7%82%B9/show_hu1979835048029173979.png","permalink":"https://deisbeir.github.io/p/redis-%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"Redis 知识点"},{"content":"1. 概述 ZooKeeper 是一个开源的分布式协调服务，用于管理大型分布式系统的配置、命名、状态和组成员等。它提供了一组简单且健壮的原语，使得分布式系统中各节点可以协调它们的动作。\n2. 设计目标 ZooKeeper 的设计目标可以概括为以下几点：\n高可用性（High Availability）：ZooKeeper 集群通过冗余实现高可用性，即使部分节点故障，整个系统仍能正常工作。 高性能（High Performance）：ZooKeeper 的设计使得它能够处理大量的客户端请求。 强一致性（Strong Consistency）：ZooKeeper 保证数据在所有节点之间的一致性，即所有客户端看到的是同一份数据。 3. 数据模型 ZooKeeper 的数据模型类似于文件系统的层次结构，由一系列节点（ZNode）组成。每个 ZNode 都有一个路径唯一标识，例如 /path/to/node。\nzookeeper的数据结点可以视为树状结构(或目录)，树中的各个结点被称为znode(即zookeeper node)，一个znode可以由多个子结点。 zookeeper结点在结构上表现为树状；\n使用路径path来定位某个znode，比如/ns-1/itcast/mysqml/schemal1/table1，此处ns-1，itcast、mysql、schemal1、table1分别是根结点、2级 结点、3级结点以及4级结点；其中ns-1是itcast的父结点，itcast是ns-1的子结点，itcast是mysql的父结点\u0026hellip;.以此类推\nznode，间距文件和目录两种特点，即像文件一样维护着数据、元信息、ACL、时间戳等数据结构，又像目录一样可以作为路径标识的一部分\n3.1 一个znode大体上分为3个部分： 结点的数据：即znode data(结点path，结点data)的关系就像是Java map中的 key value关系\n结点的子结点children\n结点的状态stat：用来描述当前结点的创建、修改记录，包括cZxid、ctime等\n3.2 ZNode 类型 持久节点（Persistent Node）：创建后一直存在，直到被显式删除。（宕机仍存在） 临时节点（Ephemeral Node）：与客户端会话绑定，客户端断开连接时自动删除。（宕机或timeout时丢失） 顺序节点（Sequential Node）：在创建时自动在节点名后追加一个递增的序号。 持久顺序节点（Persistent Sequential Node） 和 临时顺序节点（Ephemeral Sequential Node）：结合了持久/临时和顺序节点的特性。 3.3 数据版本 ZooKeeper 为每个 ZNode 维护了三个版本号：\n数据版本（dataVersion）：每次数据变更时递增。 ACL 版本（aclVersion）：每次 ACL 变更时递增。 状态版本（czxid 版本）：每次节点创建或删除时递增。 4. 典型应用场景 配置管理：集中管理分布式系统的配置信息。 命名服务：为分布式系统中的服务提供统一的命名和发现机制。 分布式锁：实现分布式环境下的互斥锁。 组成员管理：动态管理分布式系统中的节点列表。 协调和通知：节点之间通过 ZooKeeper 进行协调和通知。 5. 内部机制 5.1 客户端与服务器架构 ZooKeeper 集群由多个服务器组成，每个服务器可以接受客户端的连接。客户端通过连接到任一服务器来访问 ZooKeeper 服务。客户端与服务器之间采用 TCP 连接，并且客户端会维护与服务器的心跳检测。\n5.2.1 集群角色 Leader：负责处理客户端请求，进行投票决策，维护集群状态。 Follower：跟随 Leader，接收 Leader 的指令，处理客户端请求（仅读请求）。 Observer：类似于 Follower，但不参与投票，仅用于扩展读能力。 5.2.2 集群角色 myid：每个 ZooKeeper 服务器都有一个唯一的 myid，用于标识自己。 zxid（ZooKeeper Transaction ID）：事务 ID，表示服务器上最后一次提交的事务。 epoch：逻辑时钟，用于区分不同的选举轮次。 5.3 Leader 选举 通过一种称为 Zab（ZooKeeper Atomic Broadcast）协议 的算法来实现的。Zab 协议是 ZooKeeper 的核心协议，用于保证分布式系统的一致性和可靠性。Leader 选举是 Zab 协议的重要组成部分，确保在集群中选出一个唯一的 Leader 来处理所有写请求。\nZooKeeper 的 Leader 选举分为两个阶段：\n发现阶段（Discovery Phase）：节点之间交换信息，确定当前的集群状态。 同步阶段（Synchronization Phase）：Leader 将最新的数据同步给其他节点。 5.3.1 选举触发条件 集群启动时，所有节点都处于 LOOKING 状态，开始选举。 当 Leader 宕机或失去连接时，Follower 会重新进入 LOOKING 状态，触发选举。 5.3.2 选举规则 每个节点在选举时会投票给自己或其他节点，投票的依据是：\n优先比较 zxid：zxid 最大的节点优先成为 Leader。 如果 zxid 相同，则比较 myid：myid 最大的节点优先成为 Leader。 5.3.3 选举流程 初始化状态： 所有节点启动时，初始状态为 LOOKING。 每个节点投票给自己，投票信息包括：(myid, zxid, epoch)。 交换投票信息： 节点之间通过 TCP 连接交换投票信息。 每个节点将自己的投票信息发送给其他节点。 处理投票： 每个节点收到其他节点的投票信息后，会进行比较： 如果收到的投票比自己的投票更优（zxid 更大，或者 zxid 相同但 myid 更大），则更新自己的投票。 否则，保持自己的投票不变。 统计投票： 每个节点统计收到的投票信息，如果某个节点获得了 大多数（Quorum） 的投票（即超过半数节点的支持），则该节点成为 Leader。 其他节点成为 Follower。 选举完成： 被选为 Leader 的节点状态变为 LEADING。 其他节点状态变为 FOLLOWING。 5.3.4 选举的容错机制 大多数原则（Quorum）： ZooKeeper 使用“大多数原则”来保证选举的正确性。只有获得大多数节点支持的节点才能成为 Leader。 例如，在一个 5 节点的集群中，至少需要 3 个节点同意才能选出 Leader。 防止脑裂（Split-Brain）： 通过大多数原则，ZooKeeper 可以防止网络分区导致的脑裂问题。如果集群被分割为多个部分，只有包含大多数节点的部分才能选出 Leader。 恢复机制： 如果 Leader 宕机，Follower 会重新触发选举，选出新的 Leader。 新 Leader 会通过 Zab 协议将最新的数据同步给其他节点，确保数据一致性。 5.4 数据同步 ZooKeeper 采用基于主从复制的同步机制。Leader 负责将数据变更日志（事务日志）发送给 Follower，Follower 按照相同的顺序应用日志，保证数据一致性。\n5.5 Watch 机制 ZooKeeper 提供了一种 Watch 机制，允许客户端在某个 ZNode 上注册Watcher。当 ZNode 的状态发生变化时，ZooKeeper 会向注册的客户端发送通知。\nwatcher概念 zookeeper提供了数据的 发布/订阅 功能，多个订阅者可同时监听某一特定主题对象，当该主题对象的自身状态发生变化时例如节点内容 改变、节点下的子节点列表改变等，会实时、主动通知所有订阅者 zookeeper采用了 Watcher机制实现数据的发布订阅功能。该机制在被订阅对象发生变化时会异步通知客户端，因此客户端不必在 Watcher注册后轮询阻塞，从而减轻了客户端压力 watcher机制事件上与观察者模式类似，也可看作是一种观察者模式在分布式场景下的实现方式 watcher架构 watcher实现由三个部分组成\nzookeeper服务端 zookeeper客户端 客户端的ZKWatchManager对象 客户端首先将 Watcher注册到服务端，同时将 Watcher对象保存到客户端的watch管理器中。当Zookeeper服务端监听的数据状态发生变化时， 服务端会主动通知客户端，接着客户端的 Watch管理器会触发相关 Watcher来回调相应处理逻辑，从而完成整体的数据 发布/订阅 流程。\n6. 一致性保障 ZooKeeper 通过以下机制保证数据一致性：\n原子性：所有操作要么全部成功，要么全部失败。 顺序一致性：来自同一客户端的请求按顺序执行。 强一致性：所有客户端看到的是同一份数据。 7. 优缺点 优点 简单易用：提供简单易用的 API，易于集成到分布式系统中。 高可用性：通过冗余节点保证服务的高可用性。 强一致性：保证数据在所有节点之间的一致性。 缺点 性能受限：虽然性能较高，但仍然存在单点性能瓶颈（Leader 节点）。 复杂性：内部机制相对复杂，维护成本较高。 8. 适用场景 ZooKeeper 适用于以下场景：\n配置管理：集中管理分布式系统的配置信息。 命名服务：为分布式系统中的服务提供统一的命名和发现机制。 分布式锁和协调：实现分布式环境下的互斥锁和协调机制。 集群管理：动态管理集群节点，实现故障转移和负载均衡。 9. 总结 ZooKeeper 是一个功能强大且广泛应用的分布式协调服务，适用于各种分布式系统的协调和管理。其简单易用的 API 和强大的一致性保证，使得它成为构建分布式系统的重要组件。然而，理解和正确使用 ZooKeeper 也需要一定的知识和经验，特别是在处理一致性、性能和高可用性方面。\nwatch机制demo 下面是一个使用 ZooKeeper Watch 机制的简单示例。这个示例展示了如何使用 Java 客户端连接到 ZooKeeper 服务器，并在一个节点上设置 Watcher，当节点数据发生变化时，客户端会收到通知。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 import org.apache.zookeeper.WatchedEvent; import org.apache.zookeeper.Watcher; import org.apache.zookeeper.ZooKeeper; import org.apache.zookeeper.CreateMode; import org.apache.zookeeper.ZooDefs; import org.apache.zookeeper.KeeperException; import java.io.IOException; import java.util.concurrent.CountDownLatch; public class ZookeeperWatchDemo { // ZooKeeper 连接地址 private static final String ZK_ADDRESS = \u0026#34;localhost:2181\u0026#34;; // ZooKeeper 会话超时时间 private static final int SESSION_TIMEOUT = 3000; // 用于等待连接建立的信号量 private static final CountDownLatch connectedSignal = new CountDownLatch(1); // ZooKeeper 实例 private static ZooKeeper zooKeeper; public static void main(String[] args) throws IOException, InterruptedException, KeeperException { // 创建 ZooKeeper 连接 zooKeeper = new ZooKeeper(ZK_ADDRESS, SESSION_TIMEOUT, new Watcher() { @Override public void process(WatchedEvent event) { if (event.getState() == Event.KeeperState.SyncConnected) { // 连接建立后，释放信号量 connectedSignal.countDown(); } } }); // 等待连接建立 connectedSignal.await(); System.out.println(\u0026#34;Connected to ZooKeeper!\u0026#34;); // 创建持久节点 String path = \u0026#34;/testWatchNode\u0026#34;; if (zooKeeper.exists(path, false) == null) { zooKeeper.create(path, \u0026#34;initialData\u0026#34;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(\u0026#34;Node created: \u0026#34; + path); } // 设置 Watcher watchNode(path); // 模拟节点数据变化 zooKeeper.setData(path, \u0026#34;newData\u0026#34;.getBytes(), -1); System.out.println(\u0026#34;Node data updated.\u0026#34;); // 保持程序运行，以便观察 Watcher 触发 Thread.sleep(10000); // 关闭连接 zooKeeper.close(); } /** * 设置 Watcher 监听节点数据变化 */ private static void watchNode(String path) throws KeeperException, InterruptedException { // 获取节点数据，并设置 Watcher byte[] data = zooKeeper.getData(path, new Watcher() { @Override public void process(WatchedEvent event) { if (event.getType() == Event.EventType.NodeDataChanged) { System.out.println(\u0026#34;Node data changed: \u0026#34; + event.getPath()); try { // 重新设置 Watcher watchNode(path); } catch (KeeperException | InterruptedException e) { e.printStackTrace(); } } } }, null); System.out.println(\u0026#34;Current node data: \u0026#34; + new String(data)); } } 运行结果 1 2 3 4 5 6 Connected to ZooKeeper! Node created: /testWatchNode Current node data: initialData Node data updated. Node data changed: /testWatchNode Current node data: newData 代码说明 ZooKeeper 连接： 使用 ZooKeeper 类连接到 ZooKeeper 服务器。 通过 CountDownLatch 确保连接建立后再执行后续操作。 创建节点： 使用 zooKeeper.create() 方法创建一个持久节点 /testWatchNode，并设置初始数据。 设置 Watcher： 使用 zooKeeper.getData() 方法获取节点数据，并设置一个 Watcher。 当节点数据发生变化时，Watcher 的 process() 方法会被调用，打印变化信息，并重新设置 Watcher。 模拟节点数据变化： 使用 zooKeeper.setData() 方法更新节点数据，触发 Watcher。 保持程序运行： 使用 Thread.sleep() 保持程序运行，以便观察 Watcher 触发。 关闭连接： 使用 zooKeeper.close() 方法关闭 ZooKeeper 连接。 ","date":"2024-12-15T23:39:10+08:00","image":"https://deisbeir.github.io/p/zookeeper%E7%9F%A5%E8%AF%86%E7%82%B9/show_hu5419634950751519576.png","permalink":"https://deisbeir.github.io/p/zookeeper%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"Zookeeper知识点"},{"content":"NIO 基本概念 阻塞（Block）与非阻塞（Non-Block） 阻塞和非阻塞是进程在访问数据的时候，数据是否准备就绪的一种处理方式，当数据没有准备的时候。\n阻塞：往往需要等待缓冲区中的数据准备好过后才处理其他的事情，否则一直等待在那里。\n非阻塞:当我们的进程访问我们的数据缓冲区的时候，如果数据没有准备好则直接返回，不会等待。如果数据已经准备好，也直接返回。\n阻塞 IO ：\n非阻塞 IO ：\n同步（Synchronous）与异步（Asynchronous） 同步和异步都是基于应用程序和操作系统处理 IO 事件所采用的方式。比如\n**同步：**是应用程序要直接参与 IO 读写的操作。\n**异步：**所有的 IO 读写交给操作系统去处理，应用程序只需要等待通知。\n同步方式在处理 IO 事件的时候，必须阻塞在某个方法上面等待我们的 IO 事件完成（阻塞 IO 事件或者通过轮询 IO事件的方式），对于异步来说，所有的 IO 读写都交给了操作系统。这个时候，我们可以去做其他的事情，并不需要去完成真正的 IO 操作，当操作完成 IO 后，会给我们的应用程序一个通知。\n所以异步相比较于同步带来的直接好处就是在我们处理IO数据的时候，异步的方式我们可以把这部分等待所消耗的资源用于处理其他事务，提升我们服务自身的性能。\n**同步 IO **：\n**异步 IO **：\nJava BIO与NIO对比 BIO（传统IO）： BIO是一个同步并阻塞的IO模式，传统的 java.io 包，它基于流模型实现，提供了我们最熟知的一些 IO 功能，比如File抽象、输入输出流等。交互方式是同步、阻塞的方式，也就是说，在读取输入流或者写入输出流时，在读、写动作完成之前，线程会一直阻塞在那里，它们之间的调用是可靠的线性顺序。\nNIO（Non-blocking/New I/O） NIO 是一种同步非阻塞的 I/O 模型，于 Java 1.4 中引入，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。 NIO 提供了与传统 BIO 模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发\nBIO与NIO的对比 IO模型 BIO NIO 通信 面向流 面向缓冲 处理 阻塞 IO 非阻塞 IO 触发 无 选择器 NIO 的 Server 通信的简单模型： BIO 的 Server 通信的简单模型： NIO的特点： 一个线程可以处理多个通道，减少线程创建数量； 读写非阻塞，节约资源：没有可读／可写数据时，不会发生阻塞导致线程资源的浪费 Reactor 模型 单线程的 Reactor 模型 多线程的 Reactor 模型 多线程主从 Reactor 模型 Netty 基础概念 Netty 简介 Netty 是一个 NIO 客户端服务器框架，可快速轻松地开发网络应用程序，例如协议服务器和客户端。它极大地简化和简化了网络编程，例如 TCP 和 UDP 套接字服务器。\nNetty 执行流程 Netty 核心组件 Channel Channel是 Java NIO 的一个基本构造。可以看作是传入或传出数据的载体。因此，它可以被打开或关闭，连接或者断开连接。\nEventLoop 与 EventLoopGroup EventLoop 定义了Netty的核心抽象，用来处理连接的生命周期中所发生的事件，在内部，将会为每个Channel分配一个EventLoop。\nEventLoopGroup 是一个 EventLoop 池，包含很多的 EventLoop。\nNetty 为每个 Channel 分配了一个 EventLoop，用于处理用户连接请求、对用户请求的处理等所有事件。EventLoop 本身只是一个线程驱动，在其生命周期内只会绑定一个线程，让该线程处理一个 Channel 的所有 IO 事件。\n一个 Channel 一旦与一个 EventLoop 相绑定，那么在 Channel 的整个生命周期内是不能改变的。一个 EventLoop 可以与多个 Channel 绑定。即 Channel 与 EventLoop 的关系是 n:1，而 EventLoop 与线程的关系是 1:1。\nServerBootstrap 与 Bootstrap Bootstarp 和 ServerBootstrap 被称为引导类，指对应用程序进行配置，并使他运行起来的过程。Netty处理引导的方式是使你的应用程序和网络层相隔离。\nBootstrap 是客户端的引导类，Bootstrap 在调用 bind()（连接UDP）和 connect()（连接TCP）方法时，会新创建一个 Channel，仅创建一个单独的、没有父 Channel 的 Channel 来实现所有的网络交换。\nServerBootstrap 是服务端的引导类，ServerBootstarp 在调用 bind() 方法时会创建一个 ServerChannel 来接受来自客户端的连接，并且该 ServerChannel 管理了多个子 Channel 用于同客户端之间的通信。\nChannelHandler 与 ChannelPipeline ChannelHandler 是对 Channel 中数据的处理器，这些处理器可以是系统本身定义好的编解码器，也可以是用户自定义的。这些处理器会被统一添加到一个 ChannelPipeline 的对象中，然后按照添加的顺序对 Channel 中的数据进行依次处理。\nChannelFuture Netty 中所有的 I/O 操作都是异步的，即操作不会立即得到返回结果，所以 Netty 中定义了一个 ChannelFuture 对象作为这个异步操作的“代言人”，表示异步操作本身。如果想获取到该异步操作的返回值，可以通过该异步操作对象的addListener() 方法为该异步操作添加监 NIO 网络编程框架 Netty 听器，为其注册回调：当结果出来后马上调用执行。\nNetty 的异步编程模型都是建立在 Future 与回调概念之上的。\n启动Demo 以下是一个完整的 Netty 启动 Demo，包括一个简单的 服务端 和 客户端 实现。这个 Demo 展示了如何使用 Netty 构建一个基本的网络应用。\n1. Netty 服务端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; public class NettyServer { public static void main(String[] args) throws InterruptedException { // 创建两个 EventLoopGroup EventLoopGroup bossGroup = new NioEventLoopGroup(1); // 用于处理客户端连接 EventLoopGroup workerGroup = new NioEventLoopGroup(); // 用于处理 I/O 操作 try { // 创建 ServerBootstrap ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) // 使用 NIO 传输通道 .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); // 添加字符串编解码器 pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); // 添加自定义的处理器 pipeline.addLast(new ServerHandler()); } }) .option(ChannelOption.SO_BACKLOG, 128) // 设置连接队列大小 .childOption(ChannelOption.SO_KEEPALIVE, true); // 保持长连接 // 绑定端口并启动服务端 ChannelFuture future = serverBootstrap.bind(8080).sync(); System.out.println(\u0026#34;Netty 服务端启动成功，监听端口：8080\u0026#34;); // 等待服务端关闭 future.channel().closeFuture().sync(); } finally { // 优雅关闭 EventLoopGroup bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } // 自定义的处理器 private static class ServerHandler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { // 处理接收到的消息 System.out.println(\u0026#34;服务端收到消息: \u0026#34; + msg); // 回复客户端 ctx.writeAndFlush(\u0026#34;Hello, 客户端！\u0026#34;); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { // 处理异常 cause.printStackTrace(); ctx.close(); } } } 2. Netty 客户端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import io.netty.bootstrap.Bootstrap; import io.netty.channel.*; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.codec.string.StringEncoder; public class NettyClient { public static void main(String[] args) throws InterruptedException { // 创建 EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try { // 创建 Bootstrap Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) // 使用 NIO 传输通道 .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); // 添加字符串编解码器 pipeline.addLast(new StringDecoder()); pipeline.addLast(new StringEncoder()); // 添加自定义的处理器 pipeline.addLast(new ClientHandler()); } }); // 连接服务端 ChannelFuture future = bootstrap.connect(\u0026#34;127.0.0.1\u0026#34;, 8080).sync(); System.out.println(\u0026#34;Netty 客户端启动成功，连接到服务端\u0026#34;); // 发送消息 future.channel().writeAndFlush(\u0026#34;Hello, 服务端！\u0026#34;); // 等待客户端关闭 future.channel().closeFuture().sync(); } finally { // 优雅关闭 EventLoopGroup group.shutdownGracefully(); } } // 自定义的处理器 private static class ClientHandler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { // 处理接收到的消息 System.out.println(\u0026#34;客户端收到消息: \u0026#34; + msg); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { // 处理异常 cause.printStackTrace(); ctx.close(); } } } 3. 运行步骤 启动服务端： 运行 NettyServer 类的 main 方法。 服务端会监听 8080 端口，等待客户端连接。 启动客户端： 运行 NettyClient 类的 main 方法。 客户端会连接到服务端，并发送一条消息。 查看输出： 服务端会打印：服务端收到消息: Hello, 服务端！。 客户端会打印：客户端收到消息: Hello, 客户端！。 4. 代码说明 服务端： 使用 ServerBootstrap 启动服务端。 监听 8080 端口，处理客户端连接和消息。 使用 StringDecoder 和 StringEncoder 处理字符串消息。 自定义 ServerHandler 处理业务逻辑。 客户端： 使用 Bootstrap 启动客户端。 连接到服务端的 8080 端口，发送消息。 使用 StringDecoder 和 StringEncoder 处理字符串消息。 自定义 ClientHandler 处理业务逻辑。 ","date":"2024-12-14T23:39:10+08:00","image":"https://deisbeir.github.io/p/netty%E7%9F%A5%E8%AF%86%E7%82%B9/show_hu18369183166602136193.png","permalink":"https://deisbeir.github.io/p/netty%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"Netty知识点"},{"content":"JVM 学习笔记 1. JVM 概述 JVM 是 Java Virtual Machine 的缩写，它是一个虚构出来的计算机，一种规范。Java 虚拟机（JVM）是 Java 程序运行的核心组件，负责将 Java 字节码转换为机器码并执行。JVM 提供了跨平台的能力，使得 Java 程序能够“一次编写，到处运行”。JVM 其实就类似于一台小电脑运行在 windows 或者 linux 这些操作系统环境下即可。它直接和操作系统进行交互，与硬件不直接交互，而操作系统可以帮我们完成和硬件进行交互的工作。\n1.1 Java文件是如何被运行的 比如我们现在写了一个 HelloWorld.java 好了，那这个 HelloWorld.java 抛开所有东西不谈，就类似于一个文本文件。\n而 JVM 是不认识文本文件的，所以它需要进行 编译 ，让其成为一个它会读二进制文件的 HelloWorld.class\n类加载器 如果 JVM 想要执行这个 .class 文件，需要将其装进一个 类加载器 中，它就像一个搬运工一样，会把所有的 .class 文件全部搬进 JVM 里面来。\n方法区 方法区 是用于存放类似于元数据信息方面的数据的，比如类信息，常量，静态变量，编译后代码···等\n类加载器将 .class 文件搬过来就是先丢到这一块上\n堆 堆 主要放了一些存储的数据，比如对象实例，数组···等，它和方法区都同属于 线程共享区域 。也就是说它们都是 线程不安全 的。\n栈 栈 这是我们的代码运行空间。我们编写的每一个方法都会放到 栈 里面运行。\n我们会听说过 本地方法栈 或者 本地方法接口 这两个名词，不过我们基本不会涉及这两块的内容，它俩底层是使用 C 来进行工作的，和 Java 没有太大的关系。\n程序计数器 主要就是完成一个加载工作，类似于一个指针一样的，指向下一行我们需要执行的代码。和栈一样，都是 线程独享 的，就是说每一个线程都会有自己对应的一块区域而不会存在并发和多线程的问题。\nJava 文件经过编译后变成 .class 字节码文件。\n字节码文件通过类加载器被搬运到 JVM 虚拟机中。\n虚拟机主要的 5 大块：方法区，堆都为线程共享区域，有线程安全问题，栈和本地方法栈和计数器都是独享区域，不存在线程安全问题，而 JVM 的调优主要就是围绕堆，栈两大块进行。\n2. JVM 的核心原理 2.1 类加载机制 2.1.1 类加载过程 加载（Loading）：\n通过类加载器将 .class 文件加载到内存中。 类加载器根据类的全限定名查找字节码文件，并将其转换为 JVM 内部的类对象。 加载阶段是类加载的第一步，后续的验证、准备、解析和初始化都依赖于加载的结果。 验证（Verification）：\n确保字节码符合 JVM 规范，防止恶意代码。 验证的内容包括： 文件格式验证：检查字节码文件是否符合 JVM 规范。 元数据验证：检查类的元数据是否符合 Java 语言规范。 字节码验证：检查字节码是否合法，是否存在栈溢出、类型不匹配等问题。 符号引用验证：确保符号引用能够正确解析。 准备（Preparation）：\n为静态变量分配内存并设置默认值。 例如，static int value = 123; 在准备阶段，value 会被初始化为 0，而不是 123。 如果静态变量是常量（final），则会在准备阶段直接赋值。 解析（Resolution）：\n将符号引用转换为直接引用。 符号引用是类、方法、字段的名称和描述符，直接引用是内存地址或偏移量。 解析阶段可能触发其他类的加载。 初始化（Initialization）：\n执行静态代码块和静态变量的赋值。 初始化阶段是类加载的最后一步，只有当类被主动使用时才会触发。 例如，static { value = 123; } 会在初始化阶段执行。 其中验证，准备，解析三个部分统称为连接\n类加载器的层级结构： 加载一个 Class 类的顺序也是有优先级的，类加载器从最底层开始往上的顺序是这样的\nBootstrap Class Loader：加载核心 Java 类库（如 java.lang.*），由 JVM 实现，通常用 C/C++ 编写。 Extension Class Loader：加载扩展类库（jre/lib/ext 目录下的类）。 Application Class Loader：加载应用程序类路径（Classpath）中的类。 2.1.2 双亲委派模型 类加载器在加载类时，首先委托父类加载器尝试加载，只有在父类加载器无法加载时，才由自己加载。这样做的好处是，加载位于 rt.jar 包中的类时不管是哪个加载器加载，最终都会委托到 BootStrap ClassLoader 进行加载，这样保证了使用不同的类加载器得到的都是同一个结果 优点： 保证核心类库的安全性，避免用户自定义类替换核心类。 避免重复加载，提高加载效率。 2.1.3 自定义类加载器 可以通过继承 ClassLoader 类实现自定义类加载器。 典型应用场景： 热部署：动态加载修改后的类。 隔离类加载：实现类加载的隔离，避免类冲突。 加密类加载：加载加密的字节码文件。 2.2 运行时数据区 2.2.1 方法区（Method Area） 存储类的元数据、常量、静态变量等。 在 JDK 8 之前称为“永久代（PermGen）”，之后被“元空间（Metaspace）”取代。 元空间使用本地内存，不再受 JVM 堆内存限制，减少了内存溢出的风险。 主要存储： 类的结构信息（如方法、字段、构造函数等）。 运行时常量池（Runtime Constant Pool）。 静态变量。 2.2.2 堆（Heap） 存储对象实例和数组。 是垃圾回收的主要区域。 分为新生代（Young Generation）和老年代（Old Generation）： 新生代： 分为 Eden 区和两个 Survivor 区（From 和 To）。 新创建的对象首先分配在 Eden 区。 当 Eden 区满时，触发 Minor GC，存活的对象被移动到 Survivor 区。 经过多次 Minor GC 后仍然存活的对象会被移动到老年代。 老年代： 存储长期存活的对象。 当老年代满时，触发 Full GC，回收整个堆内存。 非堆内存则为永久代。 2.2.3 栈（Stack） 是 Java 方法执行的内存模型。里面会对局部变量，动态链表，方法出口，栈的操作（入栈和出栈）进行存储，且线程独享。同时如果我们听到局部变量表，那也是在说虚拟机栈。\n每个线程拥有独立的栈，用于存储局部变量、方法调用和部分结果。 栈帧（Stack Frame）是栈的基本单位，每个方法调用对应一个栈帧。 栈帧包括： 局部变量表：存储方法的局部变量。 操作数栈：用于执行字节码指令。 动态链接：指向运行时常量池的方法引用。 方法返回地址：记录方法执行完毕后的返回地址。 对于栈来说，不存在垃圾回收。只要程序运行结束，栈的空间自然就会释放了。栈的生命周期和所处的线程是一致的。 2.2.4 程序计数器（Program Counter Register） 记录当前线程执行的字节码指令地址。 线程私有，不会发生内存溢出。 在多线程环境下，每个线程都有自己的程序计数器，用于记录线程的执行位置。 2.2.5 本地方法栈（Native Method Stack） 为本地方法（Native Method）服务，与栈类似。 本地方法是用其他语言（如 C/C++）编写的方法，通过 JNI（Java Native Interface）调用。 2.3 执行引擎 2.3.1 解释器（Interpreter） 逐行解释字节码并执行。 优点：启动速度快，适合短生命周期的应用。 缺点：执行效率较低，适合开发环境或小型应用。 2.3.2 即时编译器（JIT Compiler） 将热点代码（频繁执行的代码）编译为机器码，提高执行效率。 主要的 JIT 编译器： C1 编译器：适用于客户端应用，编译速度快，优化程度较低。 C2 编译器：适用于服务器端应用，优化程度高，编译速度较慢。 JIT 编译器的工作流程： 监控代码执行频率，识别热点代码。 将热点代码编译为机器码。 替换解释器执行的字节码，直接执行机器码。 2.3.3 垃圾回收器（Garbage Collector） 自动回收不再使用的对象，释放内存。 常见的垃圾回收算法： 标记-清除（Mark-Sweep）： 标记所有存活的对象，清除未标记的对象。 缺点：产生内存碎片。 标记-整理（Mark-Compact）： 标记所有存活的对象，将存活对象移动到内存的一端，清除剩余内存。 优点：避免内存碎片。 复制算法（Copying）： 将内存分为两块，每次只使用一块，将存活对象复制到另一块，清除当前块。 优点：避免内存碎片，适合新生代。 分代收集（Generational Collection）： 根据对象的生命周期将堆内存分为新生代和老年代，分别采用不同的垃圾回收算法。 3. JVM 在项目中的运用 3.1 JVM 调优 3.1.1 内存设置 堆内存： -Xms：初始堆大小。 -Xmx：最大堆大小。 新生代与老年代比例： -XX:NewRatio：新生代与老年代的比例。 -XX:SurvivorRatio：Eden 区与 Survivor 区的比例。 3.1.2 垃圾回收器选择 串行垃圾回收器：-XX:+UseSerialGC，适用于单核 CPU。 并行垃圾回收器：-XX:+UseParallelGC，适用于多核 CPU。 G1 垃圾回收器：-XX:+UseG1GC，适用于大内存应用。 3.2 性能监控与问题排查 3.2.1 监控工具 jstat：监控 JVM 统计信息，如堆内存使用情况、垃圾回收次数等。 jmap：生成堆内存快照，分析内存占用。 jstack：生成线程快照，排查死锁或线程阻塞问题。 VisualVM：图形化工具，监控内存、线程、CPU 使用情况。 3.2.2 常见问题与解决方案 内存泄漏：使用 jmap 生成堆转储文件，分析对象引用链，找到未释放的对象。 CPU 占用过高：使用 jstack 查看线程堆栈，定位高 CPU 占用的线程。 频繁 Full GC：调整堆内存大小或优化垃圾回收器参数。 3.3 本地方法接口（JNI） 用途：调用本地方法（如 C/C++ 代码），适用于需要高性能或调用现有库的场景。 流程： 在 Java 中声明本地方法。 使用 javah 生成头文件。 在 C/C++ 中实现本地方法。 将本地库加载到 JVM 中。 4. 实践建议 深入理解 JVM 原理：通过阅读官方文档和相关书籍，掌握 JVM 的核心概念和工作机制。 结合实际项目调优：根据应用场景调整 JVM 参数，监控性能指标，优化垃圾回收策略。 使用工具排查问题：熟练掌握 jstat、jmap、jstack 等工具，快速定位和解决性能问题。 关注 JVM 发展趋势：了解新版本 JVM 的特性和优化，如 ZGC、GraalVM 等。 5. 总结 JVM 是 Java 生态系统的核心，理解其原理和调优方法对于开发高性能、稳定的 Java 应用至关重要。通过深入学习 JVM 的内存管理、类加载机制、执行引擎等核心组件，并结合实际项目中的调优和问题排查，可以显著提升应用的性能和可靠性。\n","date":"2024-12-12T17:23:34+08:00","image":"https://deisbeir.github.io/p/jvm/show_hu3054901689923059314.png","permalink":"https://deisbeir.github.io/p/jvm/","title":"Jvm"},{"content":"策略模式 模式的意图 在软件开发中，经常会遇到需要根据不同的条件来实现不同行为的场景。这种场景下，策略模式（Strategy Pattern）就是一种非常有用的设计模式。\n策略模式属于行为型模式，允许我们定义一系列算法，并将其封装在独立的策略类中，使得它们可以互相替换。通过使用策略模式，我们能够灵活地选择和切换不同的算法，而无需修改原有的代码，替代⼤量 if else 的逻辑。\n动机 当存在多种实现方式，且需要在运行时动态选择具体实现时，策略模式非常有用。例如，一个购物应用可能需要根据用户的会员等级来计算折扣，不同等级对应不同的计算方式，这时就可以使用策略模式来实现。 当存在一组类似的行为，只是实现细节略有不同，但又不希望通过继承来添加新的子类时，策略模式也很适用。它将这组行为封装在独立的策略类中，并通过委托的方式在上下文对象中使用。 例如 支付方式选择：一个电子商务平台可以根据用户的选择来使用不同的支付策略，例如信用卡支付、支付宝支付、微信支付等。 类结构 在策略模式中，有三个核心角色：上下文（Context）、策略接口（Strategy）和具体策略类（Concrete Strategy）。\n上下文（Context）：封装了具体策略的执行逻辑，提供给客户端使用的接口。上下文通常包含一个指向策略接口的引用，用于调用具体策略的方法。 策略接口（Strategy）：定义了一组算法或行为的公共接口，所有具体策略都必须实现该接口。 具体策略类（Concrete Strategy）：实现了策略接口，提供了具体的算法或行为。 代码示例 接下来以支付方式选择为例，展示代码\n上下文类\n1 2 3 4 5 6 7 8 9 10 11 12 // 上下文类 public class PaymentContext { private PaymentStrategy paymentStrategy; public PaymentContext(PaymentStrategy paymentStrategy) { this.paymentStrategy = paymentStrategy; } public void pay(double amount) { paymentStrategy.pay(amount); } } 策略接口\n1 2 3 4 //策略接口 public interface PaymentStrategy { void pay(double amount); } 策略接口实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //具体策略类 public class CreditCardPayment implements PaymentStrategy { public void pay(double amount) { System.out.println(\u0026#34;使用信用卡支付：\u0026#34; + amount); // 具体的支付逻辑 } } public class WeChatPay implements PaymentStrategy { public void pay(double amount) { System.out.println(\u0026#34;使用微信支付：\u0026#34; + amount); // 具体的支付逻辑 } } 调用\n1 2 3 4 5 6 7 8 9 10 11 12 // 使用示例 public class Main { public static void main(String[] args) { PaymentStrategy strategy = new CreditCardPayment(); PaymentContext context = new PaymentContext(strategy); context.pay(100.0); strategy = new WeChatPay(); context = new PaymentContext(strategy); context.pay(200.0); } } 输出\n1 2 使用信用卡支付：100.0 使用微信支付：200.0 策略模式的优缺点 策略模式的优点包括：\n松耦合：策略模式将不同的策略封装在独立的类中，与上下文对象解耦，增加了代码的灵活性和可维护性。 易于扩展：可以通过添加新的策略类来扩展系统的功能，无需修改现有代码。 符合开闭原则：对于新的策略，无需修改上下文对象，只需要实现新的策略接口即可。 策略模式的缺点包括：\n类数量增多：每个具体策略都需要一个独立的类，如果策略较多，将导致类的数量增加。 上层必须知道所有策略类：上层模块必须知道有哪些策略，并选择合适的策略进行使用，这与迪米特法则是相违背的。 注意事项： 如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题，否则日后的系统维护就会成为一个烫手山芋。\n策略模式的优化 使用Map取消 Context 类 我们可以将策略实现类放进 Map 中，根据 key 去选择具体的策略，就不必事先定义 Context 类。\n1 2 3 4 5 6 7 8 public static void main(String[] args) { Map\u0026lt;String, PaymentStrategy\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;CREDIT_CARD\u0026#34;, new CreditCardPayment()); map.put(\u0026#34;WECHAT_PAY\u0026#34;,new WeChatPay()); map.get(\u0026#34;CREDIT_CARD\u0026#34;).pay(100.0); map.get(\u0026#34;WECHAT_PAY\u0026#34;).pay(200.0); } 策略枚举解决策略类膨胀 策略枚举可以解决策略类过多的问题。\n我们对原装的策略模式进行改造，把原有定义在抽象策略中的方法移植到枚举中，让枚举成员成为一个具体策略。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Slf4j public enum PaymentStrategyEnum { CREDIT_CARD { @Override public void pay(double amount) { log.info(\u0026#34;使用信用卡支付：\u0026#34; + amount); // 具体的支付逻辑 } }, WECHAT_PAY { @Override public void pay(double amount) { log.info(\u0026#34;使用微信支付：\u0026#34; + amount); // 具体的支付逻辑 } }; public abstract void pay(double amount); } 在上面的代码中，我们定义了一个枚举类型 PaymentStrategy，其中包含两个枚举常量 CREDIT_CARD 和 WECHAT_PAY。每个枚举常量都重写了 pay() 方法，用于具体的支付逻辑\n1 2 3 4 5 6 7 8 9 // 使用示例 public static void main(String[] args) { Map\u0026lt;String, PaymentStrategyEnum\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;CREDIT_CARD\u0026#34;, PaymentStrategyEnum.CREDIT_CARD); map.put(\u0026#34;WECHAT_PAY\u0026#34;, PaymentStrategyEnum.WECHAT_PAY); map.get(\u0026#34;CREDIT_CARD\u0026#34;).pay(100.0); map.get(\u0026#34;WECHAT_PAY\u0026#34;).pay(200.0); } 注意：策略枚举是一个非常优秀和方便的模式，但是它受枚举类型的限制，每个枚举项都是 public、final、static 的，扩展性受到了一定的约束，因此在系统开发中，策略枚举一般担当不经常发生变化的角色。\nSpringBoot中的策略模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public interface Test { void print(String name); } @Service(\u0026#34;testA\u0026#34;) @Slf4j public class TestA implements Test{ @Override public void print(String name) { log.info(\u0026#34;实现类A\u0026#34;+name); } } @Service(\u0026#34;testB\u0026#34;) @Slf4j public class TestB implements Test{ @Override public void print(String name) { log.info(\u0026#34;实现类B\u0026#34;+name); } } 使用的时候 @Autowired 或者 @Resource 即可，SpringBoot会帮我们把实现类自动注入注入Map。\n1 2 3 4 5 @Resource private Map\u0026lt;String,Test\u0026gt; map; Test test = map.get(\u0026#34;你想拿出的具体策略类\u0026#34;); test.print(\u0026#34;hello world\u0026#34;); 总结 策略模式是一种强大而灵活的设计模式，它可以帮助我们处理不同的算法或行为，并使系统更具可维护性和扩展性。通过封装具体的策略类和使用上下文对象，我们可以轻松地选择和切换不同的策略，而无需修改现有的代码。\n","date":"2024-12-10T23:48:54+08:00","image":"https://deisbeir.github.io/p/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/show_hu7614944383175808824.png","permalink":"https://deisbeir.github.io/p/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","title":"策略模式"},{"content":"常见设计模式总结 我打算再理一遍常见的设计模式以加深印象，在这里先记录最基本的一些概念。\n什么是设计模式？ 设计模式是软件设计中常见问题的典型解决方案。它们就像预制的蓝图，你可以根据需要进行定制，以解决代码中反复出现的设计问题。\n模式不是一段具体的代码，而是一个解决特定问题的通用概念。你可以遵循模式的思路，实现一个适合你自己程序实际情况的解决方案。\n为什么应该学习设计模式？ 设计模式是解决软件设计中常见问题的经过验证的工具包。它会教你如何使用面向对象设计的原则来解决各种问题。\n设计模式定义了一种通用的语言，团队成员可以使用它更高效地进行沟通。能更好的应对变更。同时在解决某些问题时会给出灵感。\n实际上，不使用设计模式也可以完成很多程序、项目，但使用设计模式会帮你避免后续的很多麻烦、节约沟通成本、使你的代码更加优雅。\n每个设计模式都可以通过以下几个部分来理解 模式的意图：简要描述问题和解决方案。 动机：进一步解释问题以及模式如何提供解决方案。 类结构：展示模式中每个部分以及它们之间的关系。 代码示例：使用一种流行的编程语言编写的代码示例，帮助更容易理解模式背后的思想。 七大设计原则 单一职责原则**（Single Responsibility Principle, SRP）** 一个类应该只有一个引起它变化的原因。\n单一职责原则又称单一功能原则。这里的职责是指类变化的原因，单一职责原则规定一个类应该有且仅有一个引起它变化的原因，否则类应该被拆分（There should never be more than one reason for a class to change）。\n职责： 职责是指类或模块的功能或任务。 单一职责： 一个类或模块应该只负责一项功能或任务，而不是将多个功能或任务耦合在一起。 为什么需要单一职责原则 提高代码的可维护性： 当一个类只负责一项职责时，修改代码的影响范围更小，降低了引入新错误的风险。 提高代码的可复用性： 职责单一的类更容易被复用，因为它们的功能更加明确和独立。 降低耦合性： 职责单一的类与其他类的依赖关系更少，降低了系统的耦合性。 提高代码的可读性： 职责单一的类更容易理解和维护，因为它们的代码更加简洁和清晰。 该原则提出对象不应该承担太多职责，如果一个对象承担了太多的职责，至少存在以下两个缺点：\n一个职责的变化可能会削弱或者抑制这个类实现其他职责的能力； 当客户端需要该对象的某一个职责时，不得不将其他不需要的职责全都包含进来，从而造成冗余代码或代码的浪费。 开放封闭原则**（Open/Closed Principle, OCP）** 软件实体（类、模块、函数等）应该对扩展开放，但对修改封闭。\n软件的设计应该允许在不修改现有代码的情况下，通过扩展来增加新的功能。\n对扩展开放： 当需求变化时，可以通过添加新的代码来扩展系统的功能，而不是修改现有的代码。 对修改封闭： 现有的代码应该尽量保持稳定，避免因为需求变化而频繁修改。 为什么需要开放封闭原则 提高代码的可维护性： 减少对现有代码的修改，降低引入新错误的风险。 提高代码的可复用性： 通过扩展而不是修改，可以更好地复用现有的代码。 降低耦合性： 通过抽象和接口，减少模块之间的依赖关系。 开闭原则的实现方法：可以通过“抽象约束、封装变化”来实现开闭原则，即通过接口或者抽象类为软件实体定义一个相对稳定的抽象层，而将相同的可变因素封装在相同的具体实现类中。\n因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节可以从抽象派生来的实现类来进行扩展，当软件需要发生变化时，只需要根据需求重新派生一个实现类来扩展就可以了。\n开放封闭原则是面向对象设计中的重要原则，强调软件实体应该对扩展开放，但对修改封闭。通过使用抽象、策略模式和依赖注入等方法，可以实现开放封闭原则，提高代码的可维护性、可复用性和可扩展性。\n里式替换原则**（Liskov Substitution Principle, LSP）** 子类型必须能够替换其基类型，而不会影响程序的正确性。\n如果一个程序使用了一个基类，那么它应该能够使用该基类的任何子类，而不会产生错误或异常。\n子类型替换基类型： 子类应该能够完全替代基类，而不会影响程序的正确性。 行为一致性： 子类应该保持基类的行为规范，不能改变基类的预期行为。 为什么需要里式替换原则 提高代码的可复用性： 子类可以替代基类，使得代码更容易复用。 提高代码的可维护性： 子类保持基类的行为规范，降低了引入新错误的风险。 降低耦合性： 子类和基类之间的关系更加清晰，降低了系统的耦合性。 里式替换原则是面向对象设计中的重要原则，强调子类型必须能够替换其基类型，而不会影响程序的正确性。通过保持子类与基类的行为一致性、不强化前置条件和不弱化后置条件，可以实现里式替换原则，提高代码的可复用性、可维护性和可扩展性。\n里氏替换原则是继承复用的基础，它反映了基类与子类之间的关系，是对开闭原则的补充，是对实现抽象化的具体步骤的规范。\n迪米特法则**（Law of Demeter, LoD）** 迪米特法则（Law of Demeter，LoD）又叫作最少知识原则（Least Knowledge Principle，LKP)。\n一个对象应该对其他对象有最少的了解，只与直接的朋友通信。\n直接的朋友： 直接的朋友是指当前对象的成员变量、方法参数、方法返回值等。 最少的知识： 一个类应该只与直接的朋友交互，而不应该了解或操作朋友的朋友。 为什么需要迪米特法则 降低耦合性： 减少类之间的依赖关系，降低系统的耦合性。 提高代码的可维护性： 类的职责更加明确，修改一个类的影响范围更小。 提高代码的可复用性： 类的依赖关系更少，更容易被复用。 迪米特法则强调一个对象应该对其他对象有最少的了解，只与直接的朋友通信。通过只与直接的朋友交互和使用中介类，可以实现迪米特法则，降低系统的耦合性，提高代码的可维护性和可复用性。\n接口隔离原则**（Interface Segregation Principle, ISP）** 客户端不应该依赖于它不需要的接口。\n一个类不应该被迫实现它不需要的方法，接口应该尽量细化，每个接口只包含客户端需要的方法。\n细粒度的接口： 接口应该尽量细化，每个接口只包含客户端需要的方法。 避免臃肿的接口： 不要将多个功能耦合在一个接口中，避免客户端实现不需要的方法。 为什么需要接口隔离原则 提高代码的可维护性： 细粒度的接口更容易修改和维护，因为修改一个接口的影响范围更小。 提高代码的可复用性： 细粒度的接口更容易被复用，因为它们的功能更加明确和独立。 降低耦合性： 细粒度的接口减少了类之间的依赖关系，降低了系统的耦合性。 接口隔离原则强调客户端不应该依赖于它不需要的接口，接口应该尽量细化，每个接口只包含客户端需要的方法。通过分离接口和使用接口组合，可以实现接口隔离原则，提高代码的可维护性、可复用性和可扩展性。\n接口隔离原则和单一职责都是为了提高类的内聚性、降低它们之间的耦合性，体现了封装的思想，但两者是不同的：\n单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。 单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。 依赖倒置原则**（Dependency Inversion Principle, DIP）** 高层模块不应该依赖于低层模块，二者都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。\n设计应该依赖于抽象而不是具体实现，从而降低模块之间的耦合性，提高系统的灵活性和可维护性。\n高层模块： 高层模块是指包含业务逻辑的模块，通常负责系统的核心功能。 低层模块： 低层模块是指提供基础服务的模块，通常负责具体的实现细节。 抽象： 抽象是指接口或抽象类，定义了模块之间的契约。 细节： 细节是指具体的实现类，负责实现抽象定义的契约。 为什么需要依赖倒置原则 降低耦合性： 高层模块和低层模块都依赖于抽象，减少了模块之间的直接依赖关系。 提高代码的可维护性： 修改具体实现不会影响高层模块，降低了引入新错误的风险。 提高代码的可复用性： 抽象接口更容易被复用，因为它们不依赖于具体实现。 提高系统的灵活性： 通过替换具体实现，可以轻松扩展系统的功能。 依赖倒置原则是实现开闭原则的重要途径之一，它降低了客户与实现模块之间的耦合。\n由于在软件设计中，细节具有多变性，而抽象层则相对稳定，因此以抽象为基础搭建起来的架构要比以细节为基础搭建起来的架构要稳定得多。这里的抽象指的是接口或者抽象类，而细节是指具体的实现类。\n使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给它们的实现类去完成。\n合成复用原则**（Composite Reuse Principle, CRP）** 尽量使用对象组合（Composition）或聚合（Aggregation），而不是继承（Inheritance）来实现代码复用。\n通过将已有对象组合成新的对象来实现功能，而不是通过继承已有的类来扩展功能。\n组合（Composition）： 组合是一种强关联关系，表示整体对象拥有部分对象，部分对象的生命周期与整体对象一致。 聚合（Aggregation）： 聚合是一种弱关联关系，表示整体对象包含部分对象，但部分对象的生命周期与整体对象无关。 继承（Inheritance）： 继承是一种类与类之间的关系，子类继承父类的属性和方法。 为什么需要合成复用原则 降低耦合性： 组合和聚合比继承的耦合性更低，因为组合和聚合是通过接口或抽象类实现的，而不是直接依赖于具体实现。 提高代码的灵活性： 组合和聚合可以动态地替换部分对象，而继承是静态的，无法在运行时改变。 提高代码的可维护性： 组合和聚合使得代码更容易修改和扩展，因为修改一个类不会影响其他类。 避免继承的缺点： 继承可能导致类层次结构过于复杂，增加代码的复杂性和维护成本。 合成复用原则就是在一个新的对象里通过关联关系（包括组合关系和聚合关系）来使用一些已有的对象，使之成为新对象的一部分；新对象通过委派调用已有对象的方法达到复用功能的目的。\n简言之：复用时要尽量使用组合/聚合关系（关联关系），少用继承。\n好莱坞法则（Hollywood Principle） 不要调用我们，我们会调用你。（Don\u0026rsquo;t call us, we\u0026rsquo;ll call you.）\n高层模块（如框架或系统）负责控制流程，低层模块（如具体实现）只需提供具体的功能实现，而不需要主动调用高层模块。\n控制反转（Inversion of Control, IoC）： 好莱坞法则体现了控制反转的思想，即高层模块控制流程，低层模块被动响应。 依赖注入（Dependency Injection, DI）： 好莱坞法则通常通过依赖注入实现，高层模块将依赖注入到低层模块中，而不是低层模块主动获取依赖。 为什么需要好莱坞法则 降低耦合性： 低层模块不需要知道高层模块的存在，减少了模块之间的依赖关系。 提高代码的可维护性： 高层模块控制流程，低层模块只需关注具体实现，代码更容易修改和维护。 提高代码的可复用性： 低层模块可以在不同的高层模块中复用，因为它们不依赖于具体的高层模块。 好莱坞法则强调高层模块控制流程，低层模块被动响应，体现了控制反转和依赖注入的思想。通过好莱坞法则，可以降低模块之间的耦合性，提高代码的可维护性和可复用性。\n类图基础 1. UML 类图的基本元素 （1）类（Class） 表示：矩形框，分为三部分：\n类名：顶部，粗体显示。 属性：中间，格式为 [可见性] 属性名: 类型 [= 默认值]。 方法：底部，格式为 [可见性] 方法名(参数列表): 返回类型。 示例：\n1 2 3 4 5 6 7 8 9 +---------------------+ | Person | +---------------------+ | - name: String | | - age: int | +---------------------+ | + getName(): String | | + setAge(age: int) | +---------------------+ （2）接口（Interface） 表示：矩形框，顶部有 \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; 标识，分为两部分：\n接口名：顶部，粗体显示。 方法：底部，格式与类的方法相同。 示例：\n复制\n1 2 3 4 5 6 +---------------------+ | \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; | | Runnable | +---------------------+ | + run(): void | +---------------------+ （3）关系（Relationships） 继承（Inheritance）：\n表示：空心三角形箭头，从子类指向父类。\n实现（Implementation）：\n表示：空心三角形箭头，从实现类指向接口。\n关联（Association）：\n表示：实线箭头，从源类指向目标类，可以标注角色名和多重性。\n**「关联」**关系通常表现为类的私有属性。\n1 2 3 public class Plan { private Climate climate; } 聚合（Aggregation）：\n表示：空心菱形箭头，从整体类指向部分类。\n「聚合」 是关联关系的一种，表示一种弱的“拥有”关系。\n用Java代码表示大雁是群居动物，每只大雁都属于一个雁群，一个雁群可以有多只大雁。\n1 2 3 public class WildGooseAggregate { private List\u0026lt;WildGoose\u0026gt; wideGooses; } 组合（Composition）：\n表示：实心菱形箭头，从整体类指向部分类。\n「组合」 是关联关系的一种，表示一种强的“拥有”关系。体现了严格的部分和整体的关系。部分和整体的生命周期一样。\n1 2 3 4 5 6 public class Bird { private Wing wing; public Bird() { this.wing = new Wing(); } } 依赖（Dependency）：\n表示：虚线箭头，从依赖类指向被依赖类。\n「依赖」 关系体现为局部变量、方法的形参，或者对静态方法的调用。\n1 2 3 4 5 6 public class Programmer { public void work(Computer computer1){ //方法参数 ---- 依赖方式一 Computer computer2 = new Computer();//局部变量 ---- 依赖方式二 int price = Computer.do();//静态方法调用 ---- 依赖方式三 } } All in One的例子 前面介绍了类之间的6种关系。为了更好地理解这6种关系。下面使用一个完整的例子（汽车）。该示例中包含了这6种关系。\n说明：\n车的类图结构为，表示车是一个抽象类； 它有两个继承类：小汽车和自行车；它们之间的关系为**「实现」** 关系，使用带空心箭头的虚线表示； 小汽车为与SUV之间也是**「继承」** 关系，它们之间的关系为泛化关系，使用带空心箭头的实线表示； 小汽车与发动机之间是**「组合」** 关系，使用带实心箭头的实线表示； 学生与班级之间是**「聚合」** 关系，使用带空心箭头的实线表示； 学生与身份证之间为**「关联」** 关系，使用一根实线表示； 学生上学需要用到自行车，与自行车是一种**「依赖」** 关系，使用带箭头的虚线表示； ","date":"2024-12-10T22:54:14+08:00","image":"https://deisbeir.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9F%BA%E7%A1%80/show_hu16453722202888260347.png","permalink":"https://deisbeir.github.io/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9F%BA%E7%A1%80/","title":"设计模式基础"},{"content":"这是我的第一篇博客 我会尽可能的记录我所学习的内容！\n","date":"2024-12-10T21:48:01+08:00","permalink":"https://deisbeir.github.io/p/hellow/","title":"Hellow"}]